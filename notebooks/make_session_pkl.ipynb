{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sess class for each session and save as pickle\n",
    "\n",
    "Currently uses info from sessions_dict.py to loop through sessions and create the sess class.\n",
    "\n",
    "sess pickle files will be named `<scene>_<session>_<scan>.pickle`  \\\n",
    "and saved in `path_dict['preprocessed_root']/sess/<animal>/<date>`.\n",
    "\n",
    "Set `overwrite` to `True` if you want to overwrite existing .pickle files. Otherwise, you will get an error that the file already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from reward_relative import preprocessing as pp\n",
    "from reward_relative import utilities as ut\n",
    "\n",
    "import TwoPUtils\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify your path dictionary here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessed_root': '/data/2P',\n",
       " 'sbx_root': '/mnt/oak/InVivoDA/2P_Data',\n",
       " 'gdrive_root': '/mnt/gdrive/2P_Data',\n",
       " 'VR_Data': '/data/2P/VR_Data',\n",
       " 'git_repo_root': '/home/mari/local_repos/2p_repos',\n",
       " 'TwoPUtils': '/home/mari/local_repos/2p_repos/TwoPUtils',\n",
       " 'home': '/home/mari',\n",
       " 'fig_dir': '/data/2P/fig_scratch'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reward_relative.path_dict_firebird import path_dictionary as path_dict\n",
    "path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scroll or click to the desired section for:\n",
    "\n",
    "[Single plane](#Single-plane-sessions)\n",
    "\n",
    "[Multi plane](#Multi-plane-sessions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within each section, define animal and iterate through sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While running the below cells, if you get an error that says `DatabaseError: Execution failed on sql 'SELECT * FROM data': no such table: data`,\n",
    "check that all of your .sqlite files are named properly and have data in them (i.e. `Scene_1.sqlite` instead of `'Scene_1(1).sqlite'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single plane sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reward_relative.sessions_dict import single_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define animal\n",
    "animal = 'GCAMP15'\n",
    "days = np.arange(0, len(single_plane[animal])) # range of days\n",
    "days =days[1:3]\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 planes from scan info\n",
      "Overwriting with kwarg nplanes = 1\n",
      "Fixing teleports\n",
      "frame rate 15.5078125\n",
      "(111462,) ttl times,(23961,) ca2+ frame times\n",
      "last time: VR 1545.1188916876574, ca2+ 1545.0277078085642\n",
      "(23961, 18)\n",
      "/data/InVivoDA/GCAMP15/25_03_2024/Env1_LocationA/Env1_LocationA_002_001/suite2p\n",
      "/data/InVivoDA/sess/GCAMP15/25_03_2024\n",
      "writing Env1_LocationA_002_001.pickle\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": ".pickle already exists, aborting save. Set overwrite=True to overwrite.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-121d1c304e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                              )\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Write sess to pickle file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_sess_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local_repos/2p_repos/Sosa_et_al_2024/reward_relative/utilities.py\u001b[0m in \u001b[0;36mwrite_sess_pickle\u001b[0;34m(sess, sess_dir, pkl_name, overwrite)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkl_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             raise NotImplementedError(\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;34m\".pickle already exists, aborting save. Set overwrite=True to overwrite.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: .pickle already exists, aborting save. Set overwrite=True to overwrite."
     ]
    }
   ],
   "source": [
    "basedir = os.path.join(path_dict['preprocessed_root'], animal)\n",
    "sbxdir = os.path.join(path_dict['gdrive_root'], animal) #os.path.join(path_dict['sbx_root'], animal) # ['gdrive_root']\n",
    "vrdir = path_dict['VR_Data']\n",
    "\n",
    "binary_from_sbxdir = True # only relevant for downsampling\n",
    "calcium_exists = True\n",
    "\n",
    "load_suite2p = True\n",
    "load_scaninfo = True\n",
    "VR_only = False\n",
    "\n",
    "trial_matrix_kwargs = []\n",
    "\n",
    "for i, day in enumerate(days):\n",
    "\n",
    "    if type(single_plane[animal][day]) is not tuple:\n",
    "        date = single_plane[animal][day]['date']\n",
    "        scene = single_plane[animal][day]['scene']\n",
    "        session = single_plane[animal][day]['session']\n",
    "        scan_number = single_plane[animal][day]['scan']\n",
    "\n",
    "        sess = pp.create_sess(basedir, sbxdir, vrdir, animal, date, scene, session, scan_number,\n",
    "                              load_scaninfo=load_scaninfo,\n",
    "                              load_VR=True,\n",
    "                              load_suite2p=load_suite2p,\n",
    "                              load_behavior=True,\n",
    "                              VR_only=VR_only,                              \n",
    "                              )\n",
    "\n",
    "        sess_dir = os.path.join(\n",
    "            path_dict['preprocessed_root'], 'sess', animal, date)\n",
    "        os.makedirs(sess_dir, exist_ok=True)\n",
    "        print(sess_dir)\n",
    "\n",
    "        if np.isnan(scan_number):\n",
    "            scan_number=0\n",
    "            \n",
    "        sess_name = '%s_%03d_%03d.pickle' % (scene,\n",
    "                                             session,\n",
    "                                             scan_number\n",
    "                                             )\n",
    "        # Write sess to pickle file\n",
    "        ut.write_sess_pickle(sess, sess_dir, sess_name, overwrite=overwrite)\n",
    "\n",
    "    else:\n",
    "        print(\"Iterating through multiple sessions\")\n",
    "        for i in range(len(single_plane[animal][day])):\n",
    "            date = single_plane[animal][day][i]['date']\n",
    "            scene = single_plane[animal][day][i]['scene']\n",
    "            session = single_plane[animal][day][i]['session']\n",
    "            scan_number = single_plane[animal][day][i]['scan']\n",
    "\n",
    "            sess = pp.create_sess(basedir, sbxdir, vrdir, animal, date, scene, session, scan_number,\n",
    "                                  load_scaninfo=True,\n",
    "                                  load_VR=True,\n",
    "                                  load_suite2p=True,\n",
    "                                  load_behavior=True)\n",
    "\n",
    "            sess_dir = os.path.join(\n",
    "                path_dict['preprocessed_root'], 'sess', animal, date)\n",
    "            os.makedirs(sess_dir, exist_ok=True)\n",
    "            print(sess_dir)\n",
    "\n",
    "            sess_name = '%s_%03d_%03d.pickle' % (scene,\n",
    "                                                 session,\n",
    "                                                 scan_number,\n",
    "                                                 )\n",
    "            # Write sess to pickle file\n",
    "            ut.write_sess_pickle(\n",
    "                sess, sess_dir, sess_name, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi plane sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reward_relative.sessions_dict import multi_plane\n",
    "#multi_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal = 'GCAMP18'\n",
    "days = np.arange(0, len(multi_plane[animal])) # range of days\n",
    "nplanes = 2\n",
    "days = days[1:18] #[2:4]\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.path.join(path_dict['preprocessed_root'],animal)\n",
    "sbxdir = os.path.join(path_dict['gdrive_root'], animal) #os.path.join(path_dict['sbx_root'],animal) \n",
    "vrdir = path_dict['VR_Data']\n",
    "\n",
    "# Get data binary from basedir or sbxdir?\n",
    "binary_from_sbxdir = False\n",
    "calcium_exists = True\n",
    "add_suite2p = True\n",
    "\n",
    "for day in days: \n",
    "# day=0\n",
    "    if type(multi_plane[animal][day]) is not tuple:   \n",
    "        date = multi_plane[animal][day]['date']\n",
    "        scene = multi_plane[animal][day]['scene']\n",
    "        session = multi_plane[animal][day]['session']\n",
    "        scan_number = multi_plane[animal][day]['scan']\n",
    "\n",
    "        fullpath = os.path.join(basedir,date,scene,\"%s_%03d_%03d\" % (scene, session, scan_number))\n",
    "        scanpath = os.path.join(sbxdir,date,scene,\"%s_%03d_%03d\" % (scene, session, scan_number)) #change back to sbxdir\n",
    "\n",
    "        sess = pp.create_sess(basedir,sbxdir,vrdir,animal,date,scene,session,scan_number,\n",
    "                               load_scaninfo=True,\n",
    "                               load_VR = True,\n",
    "                               load_suite2p = add_suite2p,\n",
    "                               load_behavior = True)\n",
    "\n",
    "        nframes = int(sess.scan_info['max_idx']/sess.n_planes)\n",
    "\n",
    "        sess_dir = os.path.join(path_dict['preprocessed_root'],'sess',animal,date)\n",
    "\n",
    "        os.makedirs(sess_dir,exist_ok=True)\n",
    "        print(sess_dir)\n",
    "\n",
    "        sess_name = '%s_%03d_%03d.pickle' % (scene, \n",
    "                                             session,\n",
    "                                             scan_number,\n",
    "                                             )\n",
    "        # Write sess to pickle file\n",
    "        ut.write_sess_pickle(sess,sess_dir,sess_name,overwrite=overwrite)\n",
    "\n",
    "    else:\n",
    "        print(\"Iterating through multiple sessions\")\n",
    "        for i in range(len(multi_plane[animal][day])):\n",
    "            date = multi_plane[animal][day][i]['date']\n",
    "            scene = multi_plane[animal][day][i]['scene']\n",
    "            session = multi_plane[animal][day][i]['session']\n",
    "            scan_number = multi_plane[animal][day][i]['scan']\n",
    "\n",
    "            fullpath = os.path.join(basedir,date,scene,\"%s_%03d_%03d\" % (scene, session, scan_number))\n",
    "            scanpath = os.path.join(sbxdir,date,scene,\"%s_%03d_%03d\" % (scene, session, scan_number))\n",
    "\n",
    "            sess = pp.create_sess(basedir,sbxdir,vrdir,animal,date,scene,session,scan_number,\n",
    "                       load_scaninfo=True,\n",
    "                       load_VR = True,\n",
    "                       load_suite2p = add_suite2p,\n",
    "                       load_behavior = True)\n",
    "\n",
    "            nframes = int(sess.scan_info['max_idx']/sess.n_planes)\n",
    "\n",
    "            sess_dir = os.path.join(path_dict['preprocessed_root'],'sess',animal,multi_plane[animal][day][i]['date'])\n",
    "\n",
    "            os.makedirs(sess_dir,exist_ok=True)\n",
    "            print(sess_dir)\n",
    "\n",
    "            sess_name = '%s_%03d_%03d.pickle' % (scene, \n",
    "                                                 session,\n",
    "                                                 scan_number,\n",
    "                                                 )\n",
    "            # Write sess to pickle file\n",
    "            ut.write_sess_pickle(sess,sess_dir,sess_name,overwrite=overwrite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

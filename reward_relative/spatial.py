import TwoPUtils
import numpy as np
import scipy as sp
import warnings
import astropy
import math
from matplotlib import pyplot as plt

import TwoPUtils as tpu

from InVivoDA_analyses import behavior as behav
from . import behavior
from . import utilities as ut
from . import circ
# import TwoPUtils


def place_cell_p(cell, shuffled, direction="higher"):
    """
    p value for any metric relative to shuffle

    :param cell: metric for a single cell
    :param shuffled: set of shuffled metrics
    :param direction: direction of comparison, whether you want
        the cell's metric to be 'higher' or 'lower' than the shuffles
    :return p: p value relative to shuffle
    """

    if direction == "higher":
        # If we want higher than 95%, for instance, we can get the p value
        # by finding how many the cell's metric is LESS than
        p = (cell <= shuffled).sum()/len(shuffled)
    elif direction == "lower":
        p = (cell >= shuffled).sum()/len(shuffled)
    else:
        raise NotImplementedError("Undefined comparison direction")

    return p


def p_from_pop_shuffle(cell_SIs, perm_SIs):
    """
    Calculate place cell p values for spatial information 
    relative to shuffles from the whole population

    :param cell_SIs: spatial information for each cell; array of shape N, or Nx1
    :param perm_SIs: permuted spatial information per shuffle;
                     array of shape n_perms x n_cells (but any shape works)
    :return p_pop: array of p values per cell

    """

    all_SI_perms = np.ravel(perm_SIs)
    p_pop = np.ones((cell_SIs.shape[0],))
    for cell in range(cell_SIs.shape[0]):
        p_pop[cell] = (cell_SIs[cell] <= all_SI_perms).sum()/len(all_SI_perms)

    return p_pop


def find_reward_cells(peaks0, peaks1, rzone0, rzone1, reward_dist=50):
    """
    "Reward" cells are cells with peak firing position
    within reward_dist of the start of the reward zone
    """
    masks = np.logical_and(
        np.abs(peaks0-rzone0) <= reward_dist,
        np.abs(peaks1-rzone1) <= reward_dist
    )

    return masks


def find_stable_cells(peaks0, peaks1, rzone0, rzone1, dist=50):
    """
    "Stable" cells are cell that maintain their spatial
    firing position within dist across two sets of trials
    """
    cells_near_reward = find_reward_cells(peaks0, peaks1,
                                          rzone0, rzone1,
                                          reward_dist=dist)

    masks = np.logical_and(
        (np.abs(peaks0-peaks1) <= dist),
        ~cells_near_reward
    )

    return masks


def field_from_thresh(trial_mat, coord, cells=None,
                      prctile=0.2,
                      axis=None,
                      smooth=True,
                      sigma=2):
    """
    Calculates the field coordinates for a single place field,
    defined as activity >= prctile*(max-min)+min

    :param trial_mat: position-binned activity
    :param coord: the coordinates of the data (i.e. positions)
    :param prctile: percentile of activity change to use as threshold
    :param axis:
    :return: coordinates of the place field
    """
    fields_per_cell = {'included cells': {},
                       'number': {},
                       'widths': {},
                       'pos': {},
                       'COM': {}}

    trial_mat = np.copy(trial_mat)

    if len(trial_mat.shape) < 3:
        if len(trial_mat.shape) < 2:
            trial_mean = trial_mat
            trial_mean = np.expand_dims(trial_mean, axis=1)
            if cells is None:
                cells = [0]
        else:
            trial_mat = np.expand_dims(trial_mat, axis=2)
            trial_mean = np.nanmean(trial_mat, axis=0)
            if cells is None:
                cells = range(trial_mat.shape[2])
    else:
        trial_mean = np.nanmean(trial_mat, axis=0)
        if cells is None:
            cells = range(trial_mat.shape[2])

    if smooth:
        trial_mean = ut.nansmooth(trial_mean, sigma, axis=0)

    fields_per_cell['included cells'] = cells

    for cell in cells:
        minmax = np.nanmax(trial_mean[:, cell], axis=axis) - \
            np.nanmin(trial_mean[:, cell], axis=axis)
        thresh = prctile * minmax + np.nanmin(trial_mean[:, cell], axis=axis)
        # trying the mean of the mean firing as the thresh
        # thresh = np.nanmean(trial_mean[:, cell])

        above_thresh = np.where(trial_mean[:, cell] > thresh)[0]

        fields_inds = ut.find_contiguous(above_thresh, stepsize=1)
        # only accept fields longer than 2 bins
        fields_inds = fields_inds[[len(f) >= 2 for f in fields_inds]]
        fields_pos = []
        for f in fields_inds:
            fields_pos.append(coord[f])  # a list of arrays

        fields_per_cell['number'][cell] = len(fields_pos)
        fields_per_cell['widths'][cell] = [(f[-1] - f[0]) for f in fields_pos]
        fields_per_cell['pos'][cell] = fields_pos
        fields_per_cell['COM'][cell] = []

        # find center of mass of each field
        for field in fields_pos:
            data = trial_mean[:, cell]
            field_COM = ut.center_of_mass(
                data[np.isin(coord,
                             field)
                     ],
                coord=field,
                axis=0)
            fields_per_cell['COM'][cell].append(field_COM)

    return fields_per_cell


def calc_shuffle(activity_ts,
                 pos_ts,
                 tstart_inds,
                 teleport_inds,
                 cell_masks=None,
                 speed=None,
                 speed_thr=2,
                 nperms=100,
                 min_pos=0,
                 max_pos=450,
                 bin_size=10,
                 smooth=False,
                 sigma=2,
                 axis=None,
                 ):
    """
    Generates of matrix of binned shuffled neural activity relative to position, 
    size trials x spatial bins x cells x n permutations

    :param cells_masks: optional cell boolean mask; if None, will run for all cells
    :param activity_ts: activity timeseries (ROIs x samples)
    :param pos_ts: pos timeseries i.e. sess.vr_data['pos']
    :param trial_mat: position-binned activity for each cell (trials x bins x ROIs)
    :param coord: the coordinates of the data (i.e. positions)
    :param prctile: percentile of shuffles to use as threshold
    :param axis:
    :return: shuffled trial spatial activity matrix per cell per permutation
    """

    if cell_masks is None:
        cell_masks = np.full((activity_ts.shape[0],), True)

    nperm_trial_mat = np.zeros((len(tstart_inds),
                                len(np.arange(min_pos, max_pos +
                                              bin_size, bin_size)[:-1]),
                                len(cell_masks),
                                nperms))

    for perm in range(nperms):
        if perm % 100 == 0:
            print('perm', perm)
        perm_trial_mat, _, _, __ = tpu.spatial_analyses.trial_matrix(
            activity_ts.T, pos_ts, tstart_inds, teleport_inds, speed=speed, speed_thr=speed_thr,
            bin_size=10, min_pos=0, max_pos=450,
            perm=True)
        nperm_trial_mat[:, :, :, perm] = perm_trial_mat

    return nperm_trial_mat


def active_in_field(trial_mat,
                    pos,
                    frac_trials_thr=0.25,
                    field_thr=0.2,
                    n_std=2,
                    **kwargs
                    ):
    """
    Return bool masks for whether each cell is significantly 
    active in its place field on at least some fraction of trials
    """

    fields_per_cell = field_from_thresh(trial_mat,
                                        pos,
                                        cells=None,
                                        prctile=field_thr)

    # for each cell, find whether the original events on each trial are > n sd of the events for that trial,
    # within the positions of the field(s)
    # count number (fraction) of True trials
    # if greater than frac_trial_thr, keep place cell
    gb_masks = np.zeros(trial_mat.shape[2]).astype(bool)  # "Grienberger" masks

    for cell in fields_per_cell['number'].keys():
        thr_per_trial = (np.nanmean(trial_mat[:, :, cell], axis=1) +
                         n_std * np.nanstd(trial_mat[:, :, cell].ravel()))
        sig_bins = [(trial_mat[t, :, cell] > thr_per_trial[t]
                     )for t in range(trial_mat.shape[0])]
        # find positions of sig_bins
        sig_bins = [pos[sig_bins[t]] for t in range(len(sig_bins))]
        # find whether sig activity occurred in the cell's field
        is_active = [np.any(np.isin(sig_bins[t], np.hstack(fields_per_cell['pos'][cell]))).tolist()
                     for t in range(len(sig_bins))]
        frac_trials_active = np.sum(is_active) / len(is_active)
        gb_masks[cell] = frac_trials_active >= frac_trials_thr

    return gb_masks


def stability(trial_mat):
    """
    Calculate stability (mean trial x trial correlation) from cells' spatial activity 

    :param trial_mat: matrix of spatial activity with dimensions 
                    trials x spatial bins x cells
    """

    r_mat = np.zeros((trial_mat.shape[-1],)) * np.nan  # cells x nperms

    for c in range(trial_mat.shape[-1]):

        # Get the mean off-diag trial-by-trial correlation per cell (spatial stability)
        cell_corr_mat = corr_mat(trial_mat[:, :, c])
        off_diag = ~np.eye(cell_corr_mat.shape[0], dtype=bool)
        r_mat[c] = np.nanmean(cell_corr_mat[off_diag])

    return r_mat


def stability_pval(trial_mat, perm_mat, pthr=0.05):
    """
    Determine p values for spatial stability relative to shuffle distribution
    """

    perm_r = stability_perm(perm_mat)
    r = stability(trial_mat)

    stability_p = np.ones(r.shape)
    for cell in range(len(r)):
        stability_p[cell] = (r[cell] <= perm_r[cell, :]
                             ).sum() / len(perm_r[cell, :])

    stability_masks = stability_p < pthr

    return stability_p, stability_masks, r, perm_r


def pairwise_stability(trial_mat, trial_dict, r_thr=0.3, consec_trials=10,
                       method='consecutive'):
    """
    Calculate pairwise trial-to-trial spatial firing stability
    and mask cells that have stability > r_thr for at least consec_trials

    :param method: 'mean' (mean off-diagonal of trial-x-trial correlation matrix) or
                    'consecutive' (requires at least consec_trials above threshold)
    """

    stability_masks = {'set 0': np.full((trial_mat.shape[2],),
                                        0, dtype=bool),
                       'set 1': np.full((trial_mat.shape[2],),
                                        0, dtype=bool),
                       'thresh': r_thr,
                       'method': method
                       }

    activity_mat = ut.nansmooth(trial_mat, 2, axis=1)

    activity_mat_set0 = activity_mat[trial_dict['trial_set0'], :, :]
    activity_mat_set1 = activity_mat[trial_dict['trial_set1'], :, :]

    trial_corr = {}

    if method == 'consecutive':
        trial_corr = {'set 0': np.zeros(
            (activity_mat_set0.shape[0],
             activity_mat_set0.shape[2])
        )*np.nan,
            'set 1': np.zeros(
            (activity_mat_set1.shape[0],
             activity_mat_set1.shape[2])
        )*np.nan
        }
        for pc in range(activity_mat.shape[2]):
            # Get the mean trial-by-trial correlation per cell (spatial stability)

            for t in range(trial_corr['set 0'].shape[0]-1):
                trial_corr['set 0'][t, pc] = sp.stats.pearsonr(activity_mat_set0[t, :, pc],
                                                               activity_mat_set0[t+1, :, pc])[0]

            # Find whether there are at least 10 consecutive trials in either set
            # that have a trial-to-trial correlation of > r_thr
            find_high_trial_corr = ut.find_contiguous(
                (trial_corr['set 0'][:, pc] > r_thr)*1, stepsize=0)
            stability_masks['set 0'][pc] = np.any(np.asarray([
                arr.sum() for arr in find_high_trial_corr]) >= consec_trials)

            for t in range(trial_corr['set 1'].shape[0]-1):
                trial_corr['set 1'][t, pc] = sp.stats.pearsonr(activity_mat_set1[t, :, pc],
                                                               activity_mat_set1[t+1, :, pc])[0]
            find_high_trial_corr = ut.find_contiguous(
                (trial_corr['set 1'][:, pc] > r_thr)*1, stepsize=0)
            stability_masks['set 1'][pc] = np.any(np.asarray([
                arr.sum() for arr in find_high_trial_corr]) >= consec_trials)

    elif method == 'mean':

        trial_corr = {'set 0': np.zeros((activity_mat_set0.shape[2],))*np.nan,
                      'set 1': np.zeros((activity_mat_set1.shape[2],))*np.nan
                      }

        for pc in range(activity_mat_set0.shape[2]):
            # Get the mean trial-by-trial correlation per cell (spatial stability)
            this_cell_corr_mat = corr_mat(activity_mat_set0[:, :, pc])
            off_diag = ~np.eye(this_cell_corr_mat.shape[0], dtype=bool)
            trial_corr['set 0'][pc] = np.nanmean(
                this_cell_corr_mat[off_diag])
            stability_masks['set 0'][pc] = trial_corr['set 0'][pc] > r_thr

        for pc in range(activity_mat_set1.shape[2]):
            # Get the mean trial-by-trial correlation per cell (spatial stability)
            this_cell_corr_mat = corr_mat(activity_mat_set1[:, :, pc])
            off_diag = ~np.eye(this_cell_corr_mat.shape[0], dtype=bool)
            trial_corr['set 1'][pc] = np.nanmean(
                this_cell_corr_mat[off_diag])
            stability_masks['set 1'][pc] = trial_corr['set 1'][pc] > r_thr

    return trial_corr, stability_masks


def peak(trial_mat, coord, axis=None):
    """
    Finds the argmax of the spatial activity
    If input data are all NaNs or zeros, returns NaN.
    Note: if input data are all zeros, the first index will be returned

    :param trial_mat:
    :param coord: the coordinates of the data (i.e. position bin centers)
    :param axis:
    :return:
    """

    ind = np.asanyarray(ut.nanargmax(trial_mat, axis=axis))
    if ~np.any(np.isnan(ind)):  # if none are NaN
        peak_pos = coord[ind]
    elif np.all(np.isnan(ind)):  # if all are NaN
        peak_pos = ind
    else:  # if some are NaN
        peak_pos = np.zeros(ind.shape)*np.nan
        peak_pos[~np.isnan(ind)] = coord[~np.isnan(ind)]

    return peak_pos


def peak_hist_1d(trial_mat,
                 pos,
                 bins=np.arange(0, 460, 10),
                 smooth=False,
                 probability=True):

    mean_map = np.nanmean(trial_mat, axis=0)  # trial_mat
    pks = peak(mean_map, pos, axis=0)
    tmp_counts, _ = np.histogram(pks, bins=bins)

    if probability:
        pk_hist = tmp_counts / tmp_counts.sum()
    else:
        pk_hist = tmp_counts

    return pk_hist


def pos_cm_to_rad(pos_, max_pos, min_pos, override_warning=False):
    """
    Convert position in cm to radians, 
    measured between the min and max pos on the track;
    accepts a single position or array of positions
    """

    if max_pos < min_pos:
        # Safeguard against mis-entering coordinates and getting erroneous results
        raise NotImplementedError(
            f"Max pos {max_pos} should typically be larger than min pos {min_pos}; \n if you meant to do this, set override_warning=True")

    pos = np.copy(pos_)
    if type(pos) is list:
        pos = np.asarray(pos)

    return 2*np.pi*((pos-min_pos)/(max_pos-min_pos)) - np.pi


def dist_cm_to_rad(dist, max_pos, min_pos, override_warning=False):
    """
    Convert a distance in cm to radians

    e.g. a 50 cm span, regardless of the starting point, should elapse x radians
    """
    if max_pos < min_pos:
        # Safeguard against mis-entering coordinates and getting erroneous results
        raise NotImplementedError(
            f"Max pos {max_pos} should typically be larger than min pos {min_pos}; \n if you meant to do this, set override_warning=True")

    dist2rad = circ.phase_diff(
        pos_cm_to_rad(dist, max_pos, min_pos=min_pos),
        pos_cm_to_rad(min_pos, max_pos, min_pos=min_pos)
    )

    return dist2rad


def dist_rad_to_cm(rad, max_pos=450, min_pos=0, override_warning=False):
    """
    Convert a distance in radians to cm

    default: min pos = 0, max pos (length of track) = 450 cm
    """
    if max_pos < min_pos:
        # Safeguard against mis-entering coordinates and getting erroneous results
        raise NotImplementedError(
            f"Max pos {max_pos} should typically be larger than min pos {min_pos}; \n if you meant to do this, set override_warning=True")

    if type(rad) is list:
        rad = np.asarray(rad)

    return (rad / (2*np.pi))*(max_pos-min_pos)


def circ_peak(activity, coord, max_pos=450, min_pos=0):
    """
    Computes the circular place field peak.

    :param activity: position-binned activity, one cell at a time (a 1D array)
    :param coord: the coordinates of the data (i.e. position bin centers)

    :return: circular peak
    """
    circ_coord = pos_cm_to_rad(coord, max_pos, min_pos)
    # find max of activity in circular coordinates
    circ_peak_loc = circ_coord[ut.nanargmax(activity)]

    return circ_peak_loc, circ_coord


def trial_subset_ratemap(full_trial_mat, trial_indices=None, masks=None, sigma=2):
    """
    compute a position-binned ratemap from a subset of trials (default odd trials)

    :param full_trial_mat: position-binned trial_mat for all trials and all ROIs (3D)
    :param trial_indices: indices (or logical) of which trials to keep
    :param masks: logical of which ROIs to keep (e.g. place cells)
    :param sigma: width for gaussian smoothing (bins)
    :return:
    """

    if trial_indices is None:
        fr = np.squeeze(np.nanmean(full_trial_mat[1::2, :, :], axis=0))
    else:
        fr = np.squeeze(np.nanmean(
            full_trial_mat[trial_indices, :, :], axis=0))

    if masks is not None:
        fr = fr[:, masks]

    arr = np.copy(fr)
    arr[np.isnan(arr)] = 0.
    norms = np.amax(np.nanmean(arr, axis=0), axis=0)
    fr = fr / norms

    if sigma > 0:
        fr = ut.nansmooth(fr, sigma, axis=0)

    return fr.T


def cross_val_sort(trial_mat, axis=0):
    """
    Sort data by argmax from 50% of trials

    :param trial_mat: Assumes axis=0 (rows) are trials,
            axis=1 is time or position
            axis=2 is cells
    :param axis: axis to take trial mean across
    :return:
    """

    def getSort(fr): return np.argsort(ut.nanargmax(
        np.squeeze(np.nanmean(fr, axis=axis)), axis=axis))

    # odd trials, starting with first trial; [1::2] gives even trials
    arr = trial_mat[::2, :, :]
    arr[np.isnan(arr)] = 0
    # get peak trial-average fr for the training trials
    norms = np.amax(np.nanmean(arr, axis=0), axis=0, keepdims=True)

    # get the sort from the training trials
    sorts = getSort(arr)
    # output the sorted test trials
    test_arr = trial_mat[1::2, :, sorts]
    # get the sorted training fr to use as reference for normalization
    max_fr = norms[:, sorts]

    return sorts, test_arr, max_fr


def smooth_hist_2d(data0, data1,
                   bins=np.arange(0, 460, 10),
                   smooth=True,
                   probability=True):
    """
    Create a smoothed 2D histogram of density per position bin

    cell indices are assumed to be the same in data0 and data1

    :param data0: locations of place field peaks in track 1
    :param data1: locations of place field peaks in track 2
    :param bins: array of position bin edges
    :return: xedges,yedges,hist_sm (smoothed histogram)
    """

    # 2d histogram
    hist, xedges, yedges = np.histogram2d(
        data0, data1, bins=[bins, bins])  # ,density=True
    # smooth it
    if smooth:
        hist = sp.ndimage.filters.gaussian_filter(hist, (1, 1))

    # make it a probability
    if probability:
        hist /= hist.ravel().sum()

    return xedges, yedges, hist


def get_frac_from_2D_peak_hist(peak_hist, reward0, reward1,
                               xedges, yedges,
                               reward_dist=50,
                               bin_size=10,
                               probability=True,
                               plot_bins=False,
                               return_bin_loc=False):

    xcenters, ycenters = (xedges[:-1]+bin_size/2, yedges[:-1]+bin_size/2)

    near_reward_x = np.abs(reward0 - xcenters) <= reward_dist
    near_reward_y = np.abs(reward1 - ycenters) <= reward_dist
    near_reward = np.zeros((peak_hist.shape))
    near_reward[near_reward_x, :] += 1
    near_reward[:, near_reward_y] += 1
    near_reward = near_reward > 1

    near_diag = (np.tri(peak_hist.shape[0], k=reward_dist/bin_size, dtype=bool)
                 & ~np.tri(peak_hist.shape[0], k=-reward_dist/bin_size, dtype=bool)
                 )

    not_diag_not_reward = ~near_diag & ~near_reward
    not_diag_not_reward = not_diag_not_reward.astype(bool)

    frac_near_reward = np.nansum(peak_hist[near_reward])
    frac_near_diag = np.nansum(peak_hist[near_diag & ~near_reward])
    frac_elsewhere = np.nansum(peak_hist[not_diag_not_reward])

    # If not probability, will return whatever numbers were in the peak_hist
    if probability:
        frac_near_reward = frac_near_reward / np.nansum(peak_hist.ravel())
        frac_near_diag = frac_near_diag / np.nansum(peak_hist.ravel())
        frac_elsewhere = frac_elsewhere / np.nansum(peak_hist.ravel())

    if plot_bins:
        fig, ax = plt.subplots()
        ax.imshow(near_reward)
        ax.set_xlabel('pos trial set 2')
        ax.set_ylabel('pos trial set 0')
        ax.invert_yaxis()
        ax.set_title('reward')

        fig, ax = plt.subplots()
        ax.imshow(near_diag)
        ax.set_xlabel('pos trial set 2')
        ax.set_ylabel('pos trial set 0')
        ax.invert_yaxis()
        ax.set_title('diagonal / stable')

        fig, ax = plt.subplots()
        ax.imshow(not_diag_not_reward)
        ax.set_xlabel('pos trial set 2')
        ax.set_ylabel('pos trial set 0')
        ax.invert_yaxis()
        ax.set_title('elsewhere / remap')

    # check sum
    if probability and np.sum([frac_near_reward, frac_near_diag, frac_elsewhere]) > 1:
        print("Sum is greater than 1, something is wrong")
        print(np.sum([frac_near_reward, frac_near_diag, frac_elsewhere]))
    # print(frac_near_reward, frac_near_diag, frac_elsewhere)
    # print('fractions add up to ', np.sum([frac_near_reward, frac_near_diag, frac_elsewhere]))

    if return_bin_loc:
        bin_loc = {'near reward': near_reward,
                   'near diag': near_diag,
                   'elsewhere': not_diag_not_reward
                   }
        return frac_near_reward, frac_near_diag, frac_elsewhere, bin_loc
    else:
        return frac_near_reward, frac_near_diag, frac_elsewhere


def population_vector(pop_mat, axis=1):
    """
    Create a population vector from position-binned data by horizontally
    concatenating neurons.

    :param pop_mat: trials x pos x neurons matrix (3D)
    :return:
    """

    # Concatenate so that neurons are stacked columnwise
    PV_mat = np.concatenate([pop_mat[:, :, c]
                             for c in range(pop_mat.shape[-1])], axis=axis)
    # Get rid of nans
    PV_mat[np.isnan(PV_mat)] = 0

    return PV_mat


def cosine_similarity(mat, axis=1, zscore=False):
    """
    Calculate cosine similarity between rows of a matrix.

    :param mat: trials x position bins (or position bins * neurons) 2D matrix
    :param axis: axis to take the L2 norm across
    :param zscore: whether to zscore the cosine sim across the output matrix
    :return: trial x trial cosine similarity matrix
    """

    if len(mat.shape) != 2:
        raise NotImplementedError(
            f"Expected 2 dimensions, got {len(mat.shape)}")

    # Set nans to 0
    mat[np.isnan(mat)] = 0
    # row-wise L2 norms
    l2_norms = np.linalg.norm(mat, ord=2, axis=axis, keepdims=True)
    # divide each row of the trialxposition matrix by its L2 norm
    norm_mat = np.divide(mat, l2_norms)
    # cosine similarity
    cos_sim = norm_mat @ norm_mat.T

    if zscore:
        cos_sim = (cos_sim - np.nanmean(np.ravel(cos_sim))) / \
            np.nanstd(np.ravel(cos_sim))

    return cos_sim


def corr_mat(mat, axis=1):
    """
    Calculate correlation between rows of a matrix.

    :param mat: trials x position bins (or position bins * neurons) 2D matrix
    :param axis: axis to take the L2 norm across
    :param zscore: whether to zscore the cosine sim across the output matrix
    :return: trial x trial correlation matrix
    """

    if len(mat.shape) != 2:
        raise NotImplementedError(
            f"Expected 2 dimensions, got {len(mat.shape)}")

    # Set nans to 0
    mat[np.isnan(mat)] = 0
    # z-score matrix across columns (rows assumed to be PV on each trial)
    z_mat = ut.zscore(mat, axis=axis)
    corr = (z_mat @ z_mat.T) / (mat.shape[axis] - 1)

    return corr


def is_putative_interneuron(sess, ts_key='dff', method='speed',
                            prct=10, r_thresh=0.3):
    """
    Find putative interneurons based on either correlation of dF/F
    with speed (under the hypothesis that fast-spiking interneurons
    in the pyramidal layer are often highly correlated with running speed)
    or ratio of 99th prctile to mean spatially-binned dF/F
    values (captures cells with very high mean dF/F).

    :param sess: session class
    :param ts_key: key of timeseries to use
    :param method: method of identifying ints: 'speed' or 'trial_mat_ratio'
    :param prct: (for method 'trial_mat_ratio') percentile of ROIs within animal to cut off
    :param r_thresh: (for method 'speed') threshold for speed correlation r
    :return: is_int (list) with a Boolean for each ROI, where
        putative interneuron is True.
    """

    use_trial_mat = np.copy(sess.trial_matrices[ts_key][0])
    if method == 'trial_mat_ratio':
        trial_mat_prop = []
        trial_mat_ratio = []
        for c in range(use_trial_mat.shape[2]):
            _trial_mat = use_trial_mat[:, :, c]
            nanmask = np.isnan(_trial_mat)
            trial_mat_prop.append(np.percentile(_trial_mat[~nanmask], 75))

            trial_mat_max = np.percentile(_trial_mat[~nanmask], 99)

            ratio = trial_mat_max / np.mean(_trial_mat[~nanmask])
            trial_mat_ratio.append(ratio)

        is_int = trial_mat_ratio < np.percentile(trial_mat_ratio, prct)

    elif method == 'speed':
        speed_corr = np.zeros((use_trial_mat.shape[2],))
        speed = np.copy(sess.vr_data['speed']._values)
        nanmask = ~np.isnan(sess.timeseries[ts_key][0, :])

        for c in range(use_trial_mat.shape[2]):
            speed_corr[c] = np.corrcoef(
                sess.timeseries[ts_key][c, nanmask], speed[nanmask])[0, 1]

        is_int = speed_corr > r_thresh

    return is_int


def run_cell_classes(anim_list, multi_anim_sess, peaks_set0, peaks_set1, is_int,
                     inclusive_dist=50, ts_key='dff'):
    """
    Run get_cell_classes across multiple animals
    NOTE: the should be thought of as "remapping categories" not cell classes in the 
    sense that the cells "do this and nothing else". "Cell classes" is just shorter and
    easier to remember in code.
    """
    cell_class_masks = {}
    cell_class_fractions_total = {}  # fraction out of the total n cells
    # fraction of of place cells with sig. SI before OR after the reward switch
    cell_class_fractions_placeor = {}

    for an in anim_list:

        cell_class_masks[an], cell_class_fractions_placeor[an], cell_class_fractions_total[an] = get_cell_classes(
            multi_anim_sess[an], peaks_set0[an], peaks_set1[an], is_int[an],
            inclusive_dist=inclusive_dist, ts_key=ts_key)

    return cell_class_masks, cell_class_fractions_placeor, cell_class_fractions_total


def get_cell_classes(anim_sess, peaks_set0, peaks_set1, is_int,
                     inclusive_dist=50, ts_key='dff'):
    """
    Classifies cells based on remapping phenotype before vs. after a reward switch

    :param anim_list: list of animal names
    :param multi_anim_sess: multi-animal dictionary containing session data for a single day, 
        commonly called "all_anim"
    :param peaks_set0, peaks_set1: position bins of peak firing for each cell, in each trial set
        0 is before switch, 1 is after switch; 
        should be a dictionary with animals as keys
    :param is_int: Boolean for each cell of whether it is a putative interneuron;
        should be a dictionary with animals as keys
    :param inclusive_dist: the distance threshold between place field peaks before and after
        for calling a cell "reward" or "stable"
    :param r_thresh: (for method 'speed') threshold for speed correlation r
    :return: cell_class_masks: dictionary of boolean masks for each cell and type, for each animal
    """

    cell_class_masks = {'track_relative': {},
                        'appear': {},
                        'disappear': {},
                        'reward': {},
                        'nonreward_remap': {},
                        'not_place_cells': {},
                        }

    cell_class_fractions_total = {'track_relative': {},
                                  'appear': {},
                                  'disappear': {},
                                  'reward': {},
                                  'nonreward_remap': {},
                                  'not_place_cells': {},
                                  }

    cell_class_fractions_placeor = {'track_relative': {},
                                    'appear': {},
                                    'disappear': {},
                                    'reward': {},
                                    'nonreward_remap': {},
                                    }

    rzone0 = anim_sess['rzone'][anim_sess
                                ['trial dict']['trial_set0']][0][0]
    rzone1 = anim_sess['rzone'][anim_sess
                                ['trial dict']['trial_set1']][0][0]

    tmp_reward = find_reward_cells(peaks_set0, peaks_set1,
                                   rzone0, rzone1,
                                   reward_dist=inclusive_dist)
    tmp_reward = np.logical_and(tmp_reward, ~is_int)
    cell_class_masks['reward'] = np.logical_and(tmp_reward,
                                                np.logical_and(
                                                    anim_sess['pc masks set0'],
                                                    anim_sess['pc masks set1']
                                                )
                                                )

    tmp_stable = find_stable_cells(peaks_set0, peaks_set1,
                                   rzone0, rzone1,
                                   dist=inclusive_dist)
    tmp_stable = np.logical_and(tmp_stable, ~is_int)
    cell_class_masks['track_relative'] = np.logical_and(tmp_stable,
                                                np.logical_and(
                                                    anim_sess['pc masks set0'],
                                                    anim_sess['pc masks set1']
                                                )
                                                )

    tmp_nonrewardremap = np.logical_and(
        np.logical_and(~tmp_stable, ~tmp_reward), ~is_int)
    cell_class_masks['nonreward_remap'] = np.logical_and(tmp_nonrewardremap,
                                                         np.logical_and(
                                                             anim_sess['pc masks set0'],
                                                             anim_sess['pc masks set1']
                                                         )
                                                         )

    mean_set0 = np.nanmean(
        np.nanmean(
            anim_sess['sess'].trial_matrices[ts_key][0][anim_sess
                                                        ['trial dict']['trial_set0'], :, :],
            axis=1),
        axis=0)
    mean_set1 = np.nanmean(
        np.nanmean(
            anim_sess['sess'].trial_matrices[ts_key][0][anim_sess
                                                        ['trial dict']['trial_set1'], :, :],
            axis=1),
        axis=0)
    sd_set0 = np.nanstd(
        np.nanmean(
            anim_sess['sess'].trial_matrices[ts_key][0][anim_sess
                                                        ['trial dict']['trial_set0'], :, :],
            axis=1),
        axis=0)
    prct50_set0 = np.nanpercentile(np.nanmean(
        anim_sess['sess'].trial_matrices[ts_key][0][anim_sess
                                                    ['trial dict']['trial_set0'], :, :],
        axis=1), 50, axis=0)

    # Trial set 1 mean must be > (trial set 0 mean + 1sd)
    tmp_appear = np.logical_and(mean_set1 > (mean_set0 + sd_set0),
                                np.logical_and(
        ~anim_sess['pc masks set0'],
        anim_sess['pc masks set1']
    )
    )
    cell_class_masks['appear'] = np.logical_and(tmp_appear,
                                                ~is_int
                                                )

    # Trial set 1 mean must be < 50th percetile of mean FR per trial in set 0
    tmp_disappear = np.logical_and(mean_set1 < prct50_set0,  # - sd_set0),
                                   np.logical_and(
                                       anim_sess['pc masks set0'],
                                       ~anim_sess['pc masks set1']
                                   )
                                   )
    cell_class_masks['disappear'] = np.logical_and(tmp_disappear,
                                                   ~is_int
                                                   )

    cell_class_masks['not_place_cells'] = np.logical_and(
        ~anim_sess['pc masks set0'],
        ~anim_sess['pc masks set0']
    )

    for key in cell_class_masks.keys():
        cell_class_fractions_total[key] = cell_class_masks[key].sum(
        ) / len(cell_class_masks[key])

    for key in cell_class_fractions_placeor.keys():
        cell_class_fractions_placeor[key] = cell_class_masks[key].sum(
        ) / np.logical_and(np.logical_or(
            anim_sess['pc masks set0'],
            anim_sess['pc masks set1']),
            ~is_int
        ).sum()

    return cell_class_masks, cell_class_fractions_placeor, cell_class_fractions_total


def circ_shift_trial_matrix(sess,
                            ts_key='events',
                            pos=None,
                            max_pos=None,
                            min_pos=None,
                            circ_bin_size=None,
                            align_to='reward',
                            keep_teleports=False,
                            use_speed_thr=True,
                            **kwargs):
    """
    Compute a trial matrix in circular coordinates and circularly shift the second trial set 
        to align both sets at some feature (e.g. the starts of the reward zones).
    Assumes the timeseries to use has been added to sess.
    """

    if align_to == 'reward':
        # assuming we want to align to reward if no positions were given
        reward_zone, _ = behavior.get_reward_zones(sess)

    if max_pos is None:
        # if max pos not specific, use the max position of the original trial matrix
        max_pos = sess.trial_matrices[ts_key][-2][-1]  # 450
        print("Getting max pos from an existing trial matrix...")
        print("max pos = %d" % max_pos)
    if min_pos is None:
        min_pos = sess.trial_matrices[ts_key][-2][0]
        print("min pos = %d" % min_pos)

    if circ_bin_size is None:
        lin_bin_size = np.mean(
            np.diff(sess.trial_matrices[ts_key][-2]))

        circ_bin_size = 2*np.pi/((max_pos-min_pos)/lin_bin_size)
        print("bin size = %.4f" % circ_bin_size)

    if pos is None:
        pos = np.copy(sess.vr_data['pos'].values)

    # teleport starts at -50, so add 50 to make it start at 0 and track end at 500
    circ_pos = pos_cm_to_rad(pos, max_pos, min_pos=min_pos)
    trial_dict = behavior.define_trial_subsets(sess, force_two_sets=True)
    rzone0 = np.unique(reward_zone[trial_dict['trial_set0'], :])
    rzone1 = np.unique(reward_zone[trial_dict['trial_set1'], :])

    rzone_diff = rzone0[0] - rzone1[0]

    circ_rzone0 = pos_cm_to_rad(rzone0, max_pos, min_pos=min_pos)
    circ_rzone1 = pos_cm_to_rad(rzone1, max_pos, min_pos=min_pos)

    if keep_teleports:
        tstart_inds = sess.teleport_inds[:-1]
        tstop_inds = sess.teleport_inds[1:] - 1
        trial_set0 = trial_dict['trial_set0'][1:]
        trial_set1 = trial_dict['trial_set1'][1:]
        reward_zone = reward_zone[1:, :]
    else:
        tstart_inds = sess.trial_start_inds
        tstop_inds = sess.teleport_inds
        trial_set0 = trial_dict['trial_set0']
        trial_set1 = trial_dict['trial_set1']

    if use_speed_thr:
        speed = sess.vr_data['speed'].values
    else:
        speed = None

    circ_tm = tpu.spatial_analyses.trial_matrix(sess.timeseries[ts_key].T,
                                                circ_pos,
                                                tstart_inds,
                                                tstop_inds,
                                                bin_size=circ_bin_size,
                                                min_pos=-np.pi,
                                                max_pos=np.pi,
                                                speed_thr=2,
                                                speed=speed,
                                                **kwargs
                                                )

    # find the number of indices that aligns rzone1 with rzone 1
    if rzone0[0] > rzone1[0]:
        shift = int(np.round((circ_rzone0[0]-circ_rzone1[0])/circ_bin_size))
        trackstart_shift = circ.phase_diff(pos_cm_to_rad(np.abs(rzone_diff), max_pos, min_pos=min_pos),
                                           pos_cm_to_rad(0, max_pos, min_pos=min_pos))

    elif rzone1[0] > rzone0[0]:
        shift = -int(np.round((circ_rzone1[0]-circ_rzone0[0])/circ_bin_size))
        trackstart_shift = -circ.phase_diff(pos_cm_to_rad(np.abs(rzone_diff), max_pos, min_pos=min_pos),
                                            pos_cm_to_rad(0, max_pos, min_pos=min_pos))
    else:
        shift = 0
        trackstart_shift = 0

    circ_tm[0][trial_set1] = np.roll(
        circ_tm[0][trial_set1],
        shift,
        axis=1
    )

    circ_rzone1 = circ.wrap(
        circ_rzone1 + circ.wrap(circ_rzone0[0]-circ_rzone1[0])
    )

    aligned_loc = np.vstack((
        np.tile(np.expand_dims(circ_rzone0, 1).T,
                (len(np.where(trial_set0)[0]), 1)),
        np.tile(np.expand_dims(circ_rzone1, 1).T,
                (len(np.where(trial_set1)[0]), 1))
    ))

    trackstarts = np.zeros((reward_zone.shape[0],))
    teleports = np.zeros((reward_zone.shape[0],))

    trackstarts[trial_set0] = pos_cm_to_rad(0, max_pos, min_pos=min_pos)
    trackstarts[trial_set1] = circ.wrap(
        trackstarts[trial_set0][0] + trackstart_shift)
    teleports[trial_set0] = pos_cm_to_rad(max_pos, max_pos, min_pos=min_pos)
    teleports[trial_set1] = circ.wrap(
        teleports[trial_set0][0] + trackstart_shift)

    out = {}

    out['circ_tm'] = circ_tm
    out['aligned_locs'] = aligned_loc
    out['teleports'] = teleports
    out['trackstarts'] = trackstarts

    return out


def circ_align(data0, rzone0, data1=None, rzone1=None, max_pos=450, min_pos=0):
    """
    circularly align position data with both reward zone starts,
    such that reward is at 0 across both data sets

    inputs are specifically meant to be vectors of linear positions in cm
    """

    circ_rzone0 = pos_cm_to_rad(rzone0, max_pos, min_pos=min_pos)
    data0_aligned = pos_cm_to_rad(data0, max_pos, min_pos=min_pos)

    data0_aligned = circ.wrap(data0_aligned - circ_rzone0)

    if data1 is not None:
        circ_rzone1 = pos_cm_to_rad(rzone1, max_pos, min_pos=min_pos)
        data1_aligned = pos_cm_to_rad(data1, max_pos, min_pos=min_pos)
        data1_aligned = circ.wrap(data1_aligned - circ_rzone1)

    if data1 is None:
        return data0_aligned, circ_rzone0
    else:
        return data0_aligned, data1_aligned, circ_rzone0, circ_rzone1


def calc_place_cells(
        sess,
        ts_key='events',
        trial_subsets=False,
        nperms=100,
        output_shuffle=False,
        pos=None,
        speed=None,
        speed_thr=None,
        p_thr=0.05,
        stability_thr=None,
        shuffle_method='individual',
        include_teleports=False,
        **kwargs,
):
    """
    Place cell calculation: output boolean masks, p-values, spatial information

    :param sess: session data
    :type sess: class
    :param ts_key: 'dff' or 'events'; key of activity timeseries to use
    :type ts_key: string
    :param trial_subsets: whether to split trials into subsets
    :type trial_subsets: bool
    :param nperms: number of shuffles to perform
    :type nperms: int
    :param output_shuffle: whether to return shuffled activity matrices
    :type output_shuffle: bool
    :param speed: timeseries of speed data
    :type speed: np.array
    :param speed_thr: threshold for speed in cm/s
    :type speed_thr: float, int
    :param p_thr: p-value threshold for defining a place cell
    :type p_thr: float
    :param stability_thr: p-value threshold for mean trial-by-trial stability;
        if specified, stability r values and masks will also be returned
    :type stability_thr: float or None
    :param shuffle_method: Whether to calculate place cell significance
        of spatial information relative to the shuffle of each
        'individual' cell or the 'population' of cells
    :type shuffle_method: string
    :param kwargs: kwargs for TwoPUtils.spatial_analyses.place_cells_calc.
    :type kwargs:
    :return: pc_out dictionary:
        mask: boolean mask of whether cell is a place cell
        SI: spatial information
        p: p value from permutation
        perms: shuffled activity matrices per cell
        SI_perms: spatial information per shuffle per cell
    :rtype: dict

    """

    # Initialize defaults for place cell logical, spatial info, p-value
    masks0, SI0, p0, perms0, SI_perms0 = [], [], [], [], []
    masks1, SI1, p1, perms1, SI_perms1 = [], [], [], [], []

    stability_p0, stability_masks0, r0, perm_r0 = [], [], [], []
    stability_p1, stability_masks1, r1, perm_r1 = [], [], [], []

    activity = np.copy(sess.timeseries[ts_key]).T

    if include_teleports:
        print("Including teleport periods in place cell calc")

    if (shuffle_method == 'population') or output_shuffle:
        tmp_output_shuffle = True
    else:
        tmp_output_shuffle = False

    if speed_thr > 0:
        if speed is None:
            speed = np.copy(sess.vr_data["speed"]._values)

    if pos is None:
        pos = np.copy(sess.vr_data["pos"])

    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=RuntimeWarning)
        if trial_subsets:
            print("calculating trial subsets...")
            trial_dict = behav.define_trial_subsets(sess, force_two_sets=True)
            trial_set0 = trial_dict["trial_set0"]
            trial_set1 = trial_dict["trial_set1"]

            if include_teleports:
                # each trial is from start to next start
                t_starts0 = sess.trial_start_inds[trial_set0][:-2]
                t_ends0 = sess.trial_start_inds[trial_set0][1:][:-1]

                t_starts1 = sess.trial_start_inds[trial_set1][:-2]
                t_ends1 = sess.trial_start_inds[trial_set1][1:][:-1]
            else:
                # each trial is from start to teleport
                t_starts0 = sess.trial_start_inds[trial_set0]
                t_ends0 = sess.teleport_inds[trial_set0]

                t_starts1 = sess.trial_start_inds[trial_set1]
                t_ends1 = sess.teleport_inds[trial_set1]

        else:
            trial_set0 = np.arange(len(sess.trial_start_inds))
            if include_teleports:
                t_starts0 = sess.teleport_inds[:-1]
                t_ends0 = sess.teleport_inds[1:] - 1
            else:
                t_starts0 = np.copy(sess.trial_start_inds)
                t_ends0 = np.copy(sess.teleport_inds)

        if output_shuffle or tmp_output_shuffle:
            masks0, SI0, p0, perms0, SI_perms0 = TwoPUtils.spatial_analyses.place_cells_calc(
                activity,
                pos,
                t_starts0,
                t_ends0,
                pthr=p_thr,
                nperms=nperms,
                speed=speed,
                speed_thr=speed_thr,
                output_shuffle=tmp_output_shuffle,
                **kwargs
            )

            if stability_thr is not None:
                stability_p0, stability_masks0, r0, perm_r0 = stability_pval(
                    sess.trial_matrices[ts_key][0][trial_set0, :, :],
                    perms0,
                    pthr=stability_thr
                )

            if shuffle_method == "population":
                print("updating p with population shuffle")
                p0 = p_from_pop_shuffle(SI0, SI_perms0)
                masks0 = p0 < p_thr

            if trial_subsets:

                masks1, SI1, p1, perms1, SI_perms1 = TwoPUtils.spatial_analyses.place_cells_calc(
                    activity,
                    pos,
                    t_starts1,
                    t_ends1,
                    pthr=p_thr,
                    nperms=nperms,
                    speed=speed,
                    speed_thr=speed_thr,
                    output_shuffle=tmp_output_shuffle,
                    **kwargs
                )

                if stability_thr is not None:
                    stability_p1, stability_masks1, r1, perm_r1 = stability_pval(
                        sess.trial_matrices[ts_key][0][trial_set1, :, :],
                        perms1,
                        pthr=stability_thr
                    )

                if shuffle_method == "population":
                    p1 = p_from_pop_shuffle(SI1, SI_perms1)
                    masks1 = p1 < p_thr

        else:
            masks0, SI0, p0 = TwoPUtils.spatial_analyses.place_cells_calc(
                activity,
                pos,
                t_starts0,
                t_ends0,
                pthr=p_thr,
                nperms=nperms,
                speed=speed,
                speed_thr=speed_thr,
                **kwargs
            )

            if trial_subsets:
                masks1, SI1, p1 = TwoPUtils.spatial_analyses.place_cells_calc(
                    activity,
                    pos,
                    t_starts1,
                    t_ends1,
                    pthr=p_thr,
                    nperms=nperms,
                    speed=speed,
                    speed_thr=speed_thr,
                    **kwargs
                )

    print(f'{sum(masks0)} place cells out of {len(masks0)} in set 0')

    if not output_shuffle:
        # remove the shuffled activity matrices to save space
        perms0, perms1 = [], []

    return {
        "masks0": masks0,
        "masks1": masks1,
        "SI0": SI0,
        "SI1": SI1,
        "p0": p0,
        "p1": p1,
        "perms0": perms0,
        "perms1": perms1,
        "SI perms0": SI_perms0,
        "SI perms1": SI_perms1,
        "stability p0": stability_p0,
        "stability p1": stability_p1,
        "stability r0": r0,
        "stability r1": r1,
        "stability perm r0": perm_r0,
        "stability perm r1": perm_r1,
        "stability masks0": stability_masks0,
        "stability masks1": stability_masks1,
    }

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b935380-eed2-4030-8b33-4931465eda31",
   "metadata": {},
   "source": [
    "# Run dayData module to create multiDayData for analysis\n",
    "\n",
    "multiDayData is a dictionary where each entry holds the dayData class for a single day,  \\\n",
    "where each dayData class runs calculations such as finding circular distances between  \\\n",
    "reward-relative spatial firing peaks and comparing to a shuffle, for each animal.  \\\n",
    "Most attributes of dayData have an entry for each animal.\n",
    "\n",
    "Requires `multi_anim_sess` to already be saved for each day, which is a dictionary containing  \\\n",
    "the sess data, dF/F, and place cell booleans for each animal. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5a88c0-9791-4bee-896e-f17d6fb8703c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# inline, widget\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import dill\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "from reward_relative import utilities as ut\n",
    "from reward_relative import dayData as dd\n",
    "    \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "save_figures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d0696b-0da6-4b6c-b963-f602eea1c866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessed_root': '/data/2P',\n",
       " 'sbx_root': '/mnt/oak/InVivoDA/2P_Data',\n",
       " 'gdrive_root': '/mnt/gdrive/2P_Data',\n",
       " 'VR_Data': '/data/2P/VR_Data',\n",
       " 'git_repo_root': '/home/mari/local_repos/2p_repos',\n",
       " 'TwoPUtils': '/home/mari/local_repos/2p_repos/TwoPUtils',\n",
       " 'home': '/home/mari',\n",
       " 'fig_dir': '/data/2P/fig_scratch'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reward_relative.path_dict_firebird import path_dictionary as path_dict\n",
    "path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0f28d-4562-4dad-bf6d-560150c49741",
   "metadata": {},
   "source": [
    "# Create multiDayData class for each experiment day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89b401c0-a4d4-4395-bd1a-c43c9d99c6d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCAMP2' 'GCAMP3' 'GCAMP4' 'GCAMP5' 'GCAMP6' 'GCAMP7' 'GCAMP10' 'GCAMP11'\n",
      " 'GCAMP12' 'GCAMP13' 'GCAMP14' 'GCAMP15' 'GCAMP17' 'GCAMP18' 'GCAMP19']\n",
      "/data/2P/multi_anim_sess/2-3-4-5-6-7-10-11-12-13-14-15-17-18-19_expday3_speed2_perms100_maximin_events.pickle\n",
      "Splitting trials in half\n",
      "set 0: C trials / set 1: A trials\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: A trials / set 1: C trials\n",
      "Splitting trials in half\n",
      "set 0: A trials / set 1: C trials\n",
      "Splitting trials in half\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: B trials / set 1: C trials\n",
      "set 0: C trials / set 1: B trials\n",
      "set 0: A trials / set 1: B trials\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: B trials / set 1: C trials\n",
      "set 0: A trials / set 1: B trials\n",
      "set 0: C trials / set 1: B trials\n",
      "['GCAMP2' 'GCAMP3' 'GCAMP4' 'GCAMP6' 'GCAMP7' 'GCAMP10' 'GCAMP11'\n",
      " 'GCAMP12' 'GCAMP13' 'GCAMP14' 'GCAMP15' 'GCAMP17' 'GCAMP18' 'GCAMP19']\n",
      "/data/2P/multi_anim_sess/2-3-4-6-7-10-11-12-13-14-15-17-18-19_expday5_speed2_perms100_maximin_events.pickle\n",
      "Splitting trials in half\n",
      "set 0: A trials / set 1: B trials\n",
      "set 0: A trials / set 1: C trials\n",
      "Splitting trials in half\n",
      "set 0: C trials / set 1: B trials\n",
      "Splitting trials in half\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: C trials / set 1: A trials\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: B trials / set 1: C trials\n",
      "set 0: C trials / set 1: B trials\n",
      "set 0: C trials / set 1: A trials\n",
      "set 0: B trials / set 1: C trials\n",
      "set 0: B trials / set 1: A trials\n",
      "['GCAMP2' 'GCAMP3' 'GCAMP4' 'GCAMP6' 'GCAMP7' 'GCAMP10' 'GCAMP11'\n",
      " 'GCAMP12' 'GCAMP13' 'GCAMP14' 'GCAMP15' 'GCAMP17' 'GCAMP18' 'GCAMP19']\n",
      "/data/2P/multi_anim_sess/2-3-4-6-7-10-11-12-13-14-15-17-18-19_expday7_speed2_perms100_maximin_events.pickle\n",
      "Splitting trials in half\n",
      "set 0: B trials / set 1: C trials\n",
      "set 0: C trials / set 1: B trials\n",
      "Splitting trials in half\n",
      "set 0: B trials / set 1: A trials\n",
      "Splitting trials in half\n",
      "set 0: C trials / set 1: B trials\n",
      "set 0: A trials / set 1: B trials\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: C trials / set 1: A trials\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: A trials / set 1: B trials\n",
      "set 0: C trials / set 1: A trials\n",
      "set 0: A trials / set 1: C trials\n",
      "['GCAMP2' 'GCAMP3' 'GCAMP4' 'GCAMP6' 'GCAMP7' 'GCAMP10' 'GCAMP11'\n",
      " 'GCAMP12' 'GCAMP13' 'GCAMP14' 'GCAMP15' 'GCAMP17' 'GCAMP18' 'GCAMP19']\n",
      "/data/2P/multi_anim_sess/2-3-4-6-7-10-11-12-13-14-15-17-18-19_expday8_speed2_perms100_maximin_events.pickle\n",
      "Splitting trials in half\n",
      "set 0: C trials / set 1: B trials\n",
      "set 0: B trials / set 1: C trials\n",
      "Splitting trials in half\n",
      "set 0: A trials / set 1: B trials\n",
      "Splitting trials in half\n",
      "set 0: B trials / set 1: C trials\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: C trials / set 1: A trials\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: A trials / set 1: B trials\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: C trials / set 1: A trials\n",
      "['GCAMP2' 'GCAMP3' 'GCAMP4' 'GCAMP6' 'GCAMP7' 'GCAMP10' 'GCAMP11'\n",
      " 'GCAMP12' 'GCAMP13' 'GCAMP14' 'GCAMP15' 'GCAMP17' 'GCAMP18' 'GCAMP19']\n",
      "/data/2P/multi_anim_sess/2-3-4-6-7-10-11-12-13-14-15-17-18-19_expday10_speed2_perms100_maximin_events.pickle\n",
      "Splitting trials in half\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: C trials / set 1: A trials\n",
      "Splitting trials in half\n",
      "set 0: B trials / set 1: C trials\n",
      "Splitting trials in half\n",
      "set 0: C trials / set 1: A trials\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: A trials / set 1: B trials\n",
      "set 0: C trials / set 1: B trials\n",
      "set 0: B trials / set 1: C trials\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: C trials / set 1: B trials\n",
      "set 0: A trials / set 1: B trials\n",
      "['GCAMP2' 'GCAMP3' 'GCAMP4' 'GCAMP6' 'GCAMP7' 'GCAMP10' 'GCAMP11'\n",
      " 'GCAMP12' 'GCAMP13' 'GCAMP14' 'GCAMP15' 'GCAMP17' 'GCAMP18' 'GCAMP19']\n",
      "/data/2P/multi_anim_sess/2-3-4-6-7-10-11-12-13-14-15-17-18-19_expday12_speed2_perms100_maximin_events.pickle\n",
      "Splitting trials in half\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: A trials / set 1: B trials\n",
      "Splitting trials in half\n",
      "set 0: C trials / set 1: A trials\n",
      "Splitting trials in half\n",
      "set 0: A trials / set 1: B trials\n",
      "set 0: C trials / set 1: B trials\n",
      "set 0: B trials / set 1: C trials\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: C trials / set 1: A trials\n",
      "set 0: C trials / set 1: B trials\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: B trials / set 1: C trials\n",
      "['GCAMP2' 'GCAMP3' 'GCAMP4' 'GCAMP6' 'GCAMP7' 'GCAMP10' 'GCAMP11'\n",
      " 'GCAMP12' 'GCAMP13' 'GCAMP14' 'GCAMP15' 'GCAMP17' 'GCAMP18' 'GCAMP19']\n",
      "/data/2P/multi_anim_sess/2-3-4-6-7-10-11-12-13-14-15-17-18-19_expday14_speed2_perms100_maximin_events.pickle\n",
      "Splitting trials in half\n",
      "set 0: C trials / set 1: B trials\n",
      "set 0: B trials / set 1: C trials\n",
      "Splitting trials in half\n",
      "set 0: A trials / set 1: B trials\n",
      "Splitting trials in half\n",
      "set 0: B trials / set 1: C trials\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: C trials / set 1: A trials\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: A trials / set 1: B trials\n",
      "set 0: B trials / set 1: A trials\n",
      "set 0: A trials / set 1: C trials\n",
      "set 0: C trials / set 1: A trials\n"
     ]
    }
   ],
   "source": [
    "## Specify parameters (these are already defaults in dayData class)\n",
    "bin_size = 10  # for quantifying distribution of place field peak locations\n",
    "sigma = 1  # for smoothing\n",
    "smooth = False  # whether to smooth for finding place cell peaks\n",
    "exclude_int = True  # exclude putative interneurons\n",
    "int_thresh = 0.5\n",
    "impute_NaNs = True # whether to impute (interpolate) bins that are NaN in spatially-binned data\n",
    "\n",
    "## Place cell definitions:\n",
    "## 'and' = must have significant spatial information \n",
    "##        in trial set 0 AND trial set 1 (i.e. before and after the reward switch)\n",
    "## 'or' = must have signitive spatial information in trial set 0 OR trial set 1\n",
    "place_cell_logical = 'or' \n",
    "ts_key = 'dff' # which timeseries to use for finding peaks\n",
    "use_speed_thr = True # use a speed threshold to calculate new trial matrices\n",
    "speed_thr = 2 # speed threshold in cm/s (excludes data at speed less than this)\n",
    "\n",
    "reward_dist_inclusive = 50 #in cm\n",
    "reward_dist_exclusive = 50 #in cm\n",
    "reward_overrep_dist = 50 #in cm\n",
    "\n",
    "experiment = 'MetaLearn'\n",
    "year = 'combined'\n",
    "\n",
    "if experiment == 'NeuroMods':\n",
    "    # exp_days = [1, 3, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17]\n",
    "    exp_days = [8, 10, 12, 14, 15, 17]\n",
    "elif experiment == 'MetaLearn':\n",
    "    # exp_days = [1,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14] # all days\n",
    "    exp_days = [3, 5, 7, 8, 10, 12, 14] # switch days\n",
    "    # exp_days = [1,2,4,6,9,11,13] # \"stay\" days\n",
    "\n",
    "\n",
    "# create a tag to label the filename with params\n",
    "tag = ''\n",
    "if smooth:\n",
    "    tag = ('smoothed_sig%d' % sigma)\n",
    "else:\n",
    "    tag = 'unsmoothed'\n",
    "\n",
    "if exclude_int:\n",
    "    tag = tag + ('_excInt%.1f' % int_thresh)\n",
    "\n",
    "tag = tag + ('_inc%d' % reward_dist_inclusive)\n",
    "\n",
    "if use_speed_thr:\n",
    "    tag = tag + '_useSpeed'\n",
    "\n",
    "# For loading individual day pickles\n",
    "day_params={'speed': str(speed_thr),\n",
    "          'nperms': 100, # shuffles for defining place cells\n",
    "          'baseline_method': 'maximin', # dF/F method\n",
    "          'ts_key': 'events' # timeseries used for identifying place cells\n",
    "          }\n",
    "\n",
    "multiDayData = dict()\n",
    "\n",
    "add_all_computations = False\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    for d_i, exp_day in enumerate(exp_days):\n",
    "\n",
    "        anim_list = dd.define_anim_list(experiment, exp_day, year=year)\n",
    "\n",
    "        print(anim_list)\n",
    "\n",
    "        multi_anim_sess = dd.load_multi_anim_sess(path_dict, exp_day, anim_list,\n",
    "                                                  params=day_params\n",
    "                                                  )\n",
    "\n",
    "        # initialize class with basic info\n",
    "        multiDayData[exp_day] = dd.dayData(anim_list,\n",
    "                                           multi_anim_sess,\n",
    "                                           exp_day=exp_day,\n",
    "                                           experiment=experiment,\n",
    "                                           # timeseries to use\n",
    "                                           ts_key=ts_key,  # to use for analysis, reward cell fractions,\n",
    "                                           #                                            # finding place cell peaks\n",
    "                                           force_two_sets=True,  # of trials\n",
    "                                           use_speed_thr=use_speed_thr,\n",
    "                                           speed_thr=speed_thr,\n",
    "                                           exclude_int=exclude_int,\n",
    "                                           int_thresh=int_thresh,\n",
    "                                           int_method='speed',\n",
    "                                           reward_dist_exclusive=reward_dist_inclusive,\n",
    "                                           reward_dist_inclusive=reward_dist_exclusive,\n",
    "                                           reward_overrep_dist=reward_overrep_dist,\n",
    "                                           )\n",
    "\n",
    "        # add things to the class that are computationally intensive/time-consuming\n",
    "        if add_all_computations:\n",
    "            multiDayData[exp_day].add_all_the_things(anim_list, \n",
    "                                                    multi_anim_sess,\n",
    "                                                    add_behavior=True,\n",
    "                                                    add_cell_classes=True,\n",
    "                                                    add_circ_relative_peaks=True,\n",
    "                                                    add_field_dict=True,\n",
    "                                                    bin_size=bin_size,  # for quantifying distribution of place field peak locations\n",
    "                                                    sigma=sigma,  # for smoothing\n",
    "                                                    smooth=smooth,  # whether to smooth for finding place cell peaks\n",
    "                                                    # (activity will be auto smoothed for everything else)\n",
    "                                                    impute_NaNs=True,\n",
    "\n",
    "                                                    place_cell_logical=place_cell_logical,\n",
    "                                                    ts_key=ts_key,\n",
    "                                                    lick_correction_thr=0.35,\n",
    "                                                    )\n",
    "\n",
    "        %reset_selective -f multi_anim_sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18bb9a84-34f3-464b-aa10-eecfb80dab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['anim_list', 'experiment', 'place_cell_logical', 'force_two_sets', 'ts_key', 'use_speed_thr', 'speed_thr', 'exclude_int', 'int_thresh', 'int_method', 'reward_dist_exclusive', 'reward_dist_inclusive', 'reward_overrep_dist', 'activity_criterion', 'bin_size', 'sigma', 'smooth', 'impute_NaNs', 'sim_method', 'lick_correction_thr', 'exp_day', 'is_switch', 'anim_tag', 'trial_dict', 'rzone_pos', 'rzone_by_trial', 'rzone_label', 'blocks', 'activity_matrix', 'events', 'place_cell_masks', 'SI', 'overall_place_cell_masks', 'place_cell_trial_to_trial_stability', 'stability_masks', 'peaks', 'field_dict', 'plane_per_cell', 'is_int', 'is_reward_cell', 'is_end_cell', 'is_track_cell', 'pc_distr', 'rew_frac', 'rate_map', 'pv_sim_mean', 'sim_to_set0', 'sim_mat', 'curr_zone_lickrate', 'other_zone_lickrate', 'curr_vs_other_lickratio', 'in_vs_out_lickratio', 'lickpos_std', 'lickpos_com', 'lick_mat', 'def_block_by', 'cell_class', 'pos_bin_centers', 'dist_btwn_rel_null', 'dist_btwn_rel_peaks', 'reward_rel_cell_ids', 'xcorr_above_shuf', 'reward_rel_dist_along_unity', 'rel_peaks', 'rel_null', 'circ_licks', 'circ_speed', 'circ_map', 'circ_trial_matrix', 'circ_rel_stats_across_an'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print attributes of dayData class for day 3\n",
    "multiDayData[3].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f09edd7f-d53f-4a8c-a660-ecad2c98569a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GCAMP2',\n",
       " 'GCAMP3',\n",
       " 'GCAMP4',\n",
       " 'GCAMP5',\n",
       " 'GCAMP6',\n",
       " 'GCAMP7',\n",
       " 'GCAMP10',\n",
       " 'GCAMP11',\n",
       " 'GCAMP12',\n",
       " 'GCAMP13',\n",
       " 'GCAMP14',\n",
       " 'GCAMP15',\n",
       " 'GCAMP17',\n",
       " 'GCAMP18',\n",
       " 'GCAMP19']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_anim_list = sorted(np.unique(np.concatenate([multiDayData[day].anim_list\n",
    "                                                     for day in exp_days])), \n",
    "                           key=len)\n",
    "max_anim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbbae82f-1199-40c4-ba21-f9e0602fab83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 5, 7, 8, 10, 12, 14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiDayData.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d04b64ac-eb9d-4c2d-839d-7f95d779a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_ans = multiDayData[exp_days[-1]].circ_rel_stats_across_an['include_ans']\n",
    "include_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ada7a-1435-48c7-b8d2-d3f4629a5a92",
   "metadata": {},
   "source": [
    "## Save multiDayData as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d997bcc2-0f23-4bb5-bfd9-227839068b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-3-4-5-6-7-10-11-12-13-14-15-17-18-19_expdays3_multiDayData_dff_unsmoothed_excInt0.5_inc50_useSpeed_20240916-2202.pickle\n",
      "writing 2-3-4-5-6-7-10-11-12-13-14-15-17-18-19_expdays3_multiDayData_dff_unsmoothed_excInt0.5_inc50_useSpeed_20240916-2202.pickle\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "pkl_name = \"%s_expdays%s_multiDayData_%s_%s_%s.pickle\" % (ut.make_anim_tag(max_anim_list),\n",
    "                                                          ut.make_day_tag(\n",
    "                                                              exp_days),\n",
    "                                                          ts_key,\n",
    "                                                          tag,\n",
    "                                                          datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
    "print(pkl_name)\n",
    "file_dir = os.path.join(path_dict['preprocessed_root'], 'multiDayData')\n",
    "ut.write_sess_pickle(multiDayData, file_dir, pkl_name, overwrite=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

import os
import warnings
from abc import ABC
from glob import glob

import dill
import numpy as np
import scipy as sp
import pandas as pd
import copy
from sklearn.impute import KNNImputer
from . import utilities as ut
from . import behavior as behav
from . import spatial
from . import circ
from . import xcorr as xc
import TwoPUtils
import astropy
from astropy import stats

import dask
from dask.diagnostics import ProgressBar
from tqdm import tqdm


def define_anim_list(experiment, exp_day, year=2023):

    if experiment == 'MetaLearn':

        if year==2023:
            if exp_day in [1, 2]:
                an_list = ['GCAMP2', 'GCAMP3', 'GCAMP4', 'GCAMP5',
                           'GCAMP6', 'GCAMP7',
                           'GCAMP10', 'GCAMP12', 'GCAMP13', 'GCAMP14']
            elif exp_day == 3:
                an_list = ['GCAMP2', 'GCAMP3', 'GCAMP4', 'GCAMP5',
                           'GCAMP6', 'GCAMP7',
                           'GCAMP10', 'GCAMP11', 'GCAMP12', 'GCAMP13', 'GCAMP14']

            elif (exp_day > 3) and (exp_day <= 14):
                an_list = ['GCAMP2', 'GCAMP3', 'GCAMP4', 'GCAMP6', 'GCAMP7',
                           'GCAMP10', 'GCAMP11', 'GCAMP12', 'GCAMP13', 'GCAMP14']
            elif exp_day == 15:
                an_list = ['GCAMP10', 'GCAMP11', 'GCAMP12', 'GCAMP13', 'GCAMP14']
            else:
                raise NotImplementedError("Animal list not defined for this day")
        elif year==2024:
            an_list = ['GCAMP15', 'GCAMP17', 'GCAMP18', 'GCAMP19']
        elif year=='combined':
            if exp_day in [1, 2]:
                an_list = ['GCAMP2', 'GCAMP3', 'GCAMP4', 'GCAMP5',
                           'GCAMP6', 'GCAMP7',
                           'GCAMP10', 'GCAMP12', 'GCAMP13', 'GCAMP14',
                           'GCAMP15', 'GCAMP17', 'GCAMP18', 'GCAMP19']
            elif exp_day == 3:
                an_list = ['GCAMP2', 'GCAMP3', 'GCAMP4', 'GCAMP5',
                           'GCAMP6', 'GCAMP7',
                           'GCAMP10', 'GCAMP11', 'GCAMP12', 'GCAMP13', 'GCAMP14',
                           'GCAMP15', 'GCAMP17', 'GCAMP18', 'GCAMP19']

            elif (exp_day > 3) and (exp_day <= 14):
                an_list = ['GCAMP2', 'GCAMP3', 'GCAMP4', 'GCAMP6', 'GCAMP7',
                           'GCAMP10', 'GCAMP11', 'GCAMP12', 'GCAMP13', 'GCAMP14',
                           'GCAMP15', 'GCAMP17', 'GCAMP18', 'GCAMP19']
            elif exp_day == 15:
                an_list = ['GCAMP10', 'GCAMP11', 'GCAMP12', 'GCAMP13', 'GCAMP14',
                           'GCAMP15', 'GCAMP17', 'GCAMP18', 'GCAMP19']
            else:
                raise NotImplementedError("Animal list not defined for this day")
    else:
        raise NotImplementedError("Experiment name not defined")

    return np.asarray(an_list)


def max_anim_list(experiment, exp_days, year=2023):

    return sorted(np.unique(np.concatenate([define_anim_list(experiment,
                                                             day,
                                                            year=year)
                                            for day in exp_days])),
                  key=len)


def define_block_by(experiment, exp_day, an):

    if experiment == 'MetaLearn':
        if an in ['GCAMP2', 'GCAMP6', 'GCAMP10']:
            def_block_by = None
        else:
            if exp_day in [3, 5, 7, 8, 10, 12, 14, 15]:
                def_block_by = 'reward_zone'
            elif exp_day in [1, 2, 4, 6, 9, 11, 13]:
                def_block_by = None

    return def_block_by


def load_multi_anim_sess(path_dict, exp_day, an_list,
                         params={'speed': '2',
                                 'nperms': 100,
                                 'baseline_method': 'maximin',
                                 'ts_key': 'events'
                                 }
                         ):

    multi_an_sess = {}
    an_tag = ut.make_anim_tag(an_list)

    # load from previously saved multi_an pickle
    try:
        pkl_path = os.path.join(path_dict['preprocessed_root'], 'multi_anim_sess',
                                ('%s_expday%d_speed%s_perms%d_%s_%s.pickle' % (
                                    an_tag, exp_day, params['speed'],
                                    params['nperms'], params['baseline_method'],
                                    params['ts_key']
                                )))

        print(pkl_path)
        multi_an_sess = dill.load(open(pkl_path, "rb"))

    except:
        pkl_path = os.path.join(path_dict['preprocessed_root'], 'multi_anim_sess',
                                ('%s_expday%d_speed%s_perms%d_%s.pickle' % (
                                    an_tag, exp_day, params['speed'],
                                    params['nperms'], params['baseline_method'],
                                )))

        print(pkl_path)
        multi_an_sess = dill.load(open(pkl_path, "rb"))

    return multi_an_sess


class dayData:

    """
    Class holding an individual experiment-day's data
    for multiple animals

    Attributes:
 
    anim_list: list of mouse IDs included in this day
    experiment: experiment name ('MetaLearn')
    place_cell_logical: 'or' -- cells were classified as place cells by having 
        significant spatial information in the trials before OR after the reward switch
    force_two_sets: True -- trials were split into "set 0" for "before" the 
        reward switch, and "set 1" for after the reward switch. In animals without a reward switch, 
        "set 0" and "set 1" correspond to the 1st and 2nd half of trials, respectively
    ts_key: 'dff' -- timeseries data type (dF/F) used to find place cell peaks
    use_speed_thr: True -- whether a running speed threshold was used to quantify neural activity
    speed_thr: 2 -- the speed threshold used, in cm/s
    exclude_int: True -- whether putative interneurons were excluded from analyses
    int_thresh: 0.5 -- speed correlation threshold to identify putative interneurons
    int_method: 'speed' -- method of finding putative interneurons
    reward_dist_exclusive: 50 -- distance in cm to exclude cells "near" reward
    reward_dist_inclusive: 50 -- distance in cm to include cells as "near" reward
    reward_overrep_dist: 25 -- distance in cm for population-level quantification of reward over-representation
    activity_criterion: False -- optional additional place cell criterion based on fraction of trials active
    bin_size: 10 -- linear bin size (cm) for quantifying spatial activity
    sigma: 1 -- Gaussian s.d. in bins for smoothing
    smooth: False -- whether to smooth for finding place cell peaks
    impute_NaNs: True -- whether to impute NaN bins in spatial activity matrices
    sim_method: 'correlation' -- trial-by-trial similarity matrix method: 'cosine_sim' or 'correlation'
    lick_correction_thr: 0.35 -- threshold to detect capacitive sensor errors and set trial licking to NaN
    is_switch: whether each animal had a reward switch
    anim_tag: string of animal ID numbers
    trial_dict: dictionary of booleans identified each trial as in "set 0" or "set 1"
    rzone_pos: [start, stop] position of each reward zone (cm)
    rzone_by_trial: same as above but for each trial
    rzone_label: label of each reward zone (e.g. 'A')
    blocks: 10-trial blocks within each trial set
    activity_matrix: spatially-binned activity of type ts_key, trials x position bins x neurons 
    events: original spatially-binned deconvolved events, trials x position bins x neurons (no speed threshold applied)
    place_cell_masks: booleans of length cells identifying which cells are place cells in each trial set
    SI: spatial information for each cell in each trial set
    overall_place_cell_masks: boolean of length cells identifying which cells are place cells according to place_cell_logical
    peaks: spatial bin center of peak activity for each cell in each trial set
    field_dict: dictionary of place field properties for each cell
    plane_per_cell: imaging plane of each cell (all zeros if only a single plane was imaged, 
        otherwise 0 or 1 if two planes were imaged)
    is_int: boolean, whether each cell is a putative interneuron
    is_reward_cell: boolean, whether each cell has a peak within 50 cm of both reward zone starts
    is_end_cell: boolean, whether each cell has a peak in the first or last spatial bin of the track
    is_track_cell: boolean, whether each cell's peak stays within 50 cm of itself from trial set 0 to trial set 1
    pc_distr: binned distribution of place cell peaks along the track
    rew_frac: fraction of place cells with a peak within reward_overrep_dist of the reward zone start
    rate_map: mean deconvolved activity across the population of cells in each spatial bin
    pv_sim_mean: mean of the population vector similarity matrix in each trial block
    sim_to_set0: similarity of the population vector in each block to its activity in set 0
    sim_mat: trial-by-trial similarity matrix for place cells, licking, and speed
    curr_zone_lickrate: lickrate in the current reward zone by trial
    other_zone_lickrate: lickrate in the non-active/previous reward zone by trial
    curr_vs_other_lickratio: ratio of lickrate in the current reward zone vs. the other reward zone
    in_vs_out_lickratio: ratio of lickrate in the anticipatory zone vs. everywhere outside the anticipatory and reward zones
    lickpos_std: standard deviation of licking position
    lickpos_com: center of mass of licking position
    lick_mat: matrix of lick rate in each spatial bin by trial
    def_block_by: how to define trial blocks
    cell_class: dictionary containing booleans of which cells have remapping types classified
        as "track-relative", "disappear", "appear", "reward", or "nonreward_remap" 
        (see spatial.get_cell_classes)
    pos_bin_centers: position bin centers
    dist_btwn_rel_null: distance between spatial firing peaks before the switch 
        and the "random remapping" shuffle after the switch (radians)
    dist_btwn_rel_peaks: distance between spatial firing peaks before vs. after the switch (radians)
    reward_rel_cell_ids: integer cell indices that were identified as reward-relative after application of all criteria
    xcorr_above_shuf: lag, in spatial bins, of the above-shuffle maximum of the 
        cross-correlation used to confirm cells as reward-relative (computed for all cells; 
        NaNs indicate that the xcorr did not exceed shuffle)
    reward_rel_dist_along_unity: circular mean of pre-switch and post-switch spatial
         firing peak position relative to reward (radians)
    rel_peaks: spatial firing peak position relative to reward in each trial set (radians)
    rel_null: spatial firing peak position relative to reward, for the random-remapping shuffle post-switch (radians)
    circ_licks: spatially-binned licking, 
        in circular coordinates relative to reward (trials x position bins) 
    circ_speed: spatially-binned speed, 
        in circular coordinates relative to reward (trials x position bins) 
    circ_map: mean spatially-binned neural activity within each trial set, of type ts_key, 
        in circular coordinates relative to reward
    circ_trial_matrix: spatially-binned neural activity of type ts_key, 
        in circular coordinates relative to reward (trials x position bins x neurons) 
    circ_rel_stats_across_an: metadata across the "switch" animals:
            'include_ans': list of "switch" animal names 
            'rdist_to_rad_inc': reward_dist_inclusive converted to radians
            'rdist_to_rad_exc': reward_dist_inclusive converted to radians
            'min_pos': minimum position bin used
            'max_pos': maximum position bin used
            'hist_bin_centers': bin centers used for spatial binning

    """

    def __init__(self, an_list, multi_an_sess,
                 activity_criterion=False,
                 **kwargs):

        self.anim_list = an_list

        # ---- Initialize attributes ----
        self.experiment = None
        self.place_cell_logical = 'or'
        
        # ---- Default parameters ----
        self.force_two_sets = True
        self.ts_key = 'dff'  # to use for finding place cell peaks
        self.use_speed_thr = True
        self.speed_thr =2
        self.exclude_int = True
        self.int_thresh = 0.5
        self.int_method = 'speed'
        self.reward_dist_exclusive = 50
        self.reward_dist_inclusive = 50
        self.reward_overrep_dist = 25
        self.activity_criterion = False
        self.bin_size = 10  # for quantifying distribution of place field peak locations
        self.sigma = 1  # for smoothing
        self.smooth = False  # whether to smooth for finding place cell peaks
        # (activity will be auto smoothed for everything else)
        self.impute_NaNs=True
        # method of place map comparison across trials
        self.sim_method='correlation'  # 'cosine_sim' or 'correlation'
        self.lick_correction_thr=0.35
        
        self.__dict__.update(kwargs) # update attributes based on kwargs input
        

        # ---- Initialize dictionaries per animal ----
        self.is_switch = dict([(an, {}) for an in an_list])
        self.anim_tag = ut.make_anim_tag(an_list)
        self.trial_dict = dict([(an, {}) for an in an_list])
        self.rzone_pos = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.rzone_by_trial = dict([(an, {}) for an in an_list])
        self.rzone_label = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.blocks = dict([(an, {'set 0': {}, 'set 1': {}})
                            for an in an_list])
        # activity used for finding peaks (speed threshold applied)
        self.activity_matrix = dict([(an, {}) for an in an_list])
        # original events trial matrix, no speed threshold
        self.events = dict([(an, {}) for an in an_list])

        # update keys based on inputs
        self.__dict__.update(kwargs)

        # trial subset dictionary
        self.trial_dict = {}
        self.place_cell_masks = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.SI = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.overall_place_cell_masks = dict([(an, {}) for an in an_list])

        # # Find the cells maximal activity position for each trial set
        self.peaks = dict([(an, {'set 0': {}, 'set 1': {}})
                           for an in an_list])
        self.field_dict = dict([(an, {}) for an in an_list])
        self.plane_per_cell = dict([(an, {}) for an in an_list])
        # booleans for the whole session
        self.is_int = {}
        self.is_reward_cell = {}
        self.is_end_cell = {}
        self.is_track_cell = {}

        # place field peak distribution in each block and for each trial set
        self.pc_distr = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        # fraction of cells w/in self.reward_overrep_dist of reward zone, per block
        self.rew_frac = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        # self.rew_frac_by_trial = dict(
        #     [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        # mean population activity in each spatial bin
        self.rate_map = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        # mean PV cosine similarity in each block
        self.pv_sim_mean = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])

        self.sim_to_set0 = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        # correlation or cosine similarity matrices
        self.sim_mat = dict(
            [(an, {'pv': [], 'lick':[], 'speed':[]}) for an in an_list])

        # licking behavior
        self.curr_zone_lickrate = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.other_zone_lickrate = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.curr_vs_other_lickratio = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.in_vs_out_lickratio = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.lickpos_std = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.lickpos_com = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])
        self.lick_mat = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in an_list])

        self.def_block_by = dict([(an, define_block_by(self.experiment, self.exp_day, an))
                                  for an in an_list])

        self.cell_class = dict([(an, {}) for an in an_list])

        self.pos_bin_centers = dict([(an, {}) for an in an_list])
        
        # relative peaks relative to each other, across trials sets, for shuffle
        self.dist_btwn_rel_null = dict([(an, {}) for an in self.anim_list])
        # relative peaks relative to each other, across trials sets
        self.dist_btwn_rel_peaks = dict([(an, {}) for an in self.anim_list])
        # kept cells with both rel fields within a certain dist from reward
        self.reward_rel_cell_ids = dict([(an, {}) for an in self.anim_list])
        self.xcorr_above_shuf = dict([(an, {}) for an in self.anim_list])
        # mean distance of relative peaks along unity line
        self.reward_rel_dist_along_unity = dict([(an, {}) for an in self.anim_list])
        # peaks relative to start of reward zone, in radians
        self.rel_peaks = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in self.anim_list])
        # shuffle relative to start of reward zone
        self.rel_null = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in self.anim_list])
        # lick positions in circular coordinates (trial matrix)
        self.circ_licks = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in self.anim_list])
        # speed binned in circular coordinates (trial matrix)
        self.circ_speed = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in self.anim_list])
        # trial-averaged activity in circular coordinates
        self.circ_map = dict(
            [(an, {'set 0': {}, 'set 1': {}}) for an in self.anim_list])
        # full trial matrix in circular coordinates
        self.circ_trial_matrix = dict([(an, {}) for an in self.anim_list])
        self.circ_rel_stats_across_an = {'include_ans': [],
                                         'rdist_to_rad_inc': [],
                                         'rdist_to_rad_exc': [],
                                         'min_pos': [],
                                         'max_pos': [],
                                         'hist_bin_centers': [],
                                         
                                         }

        # ---- Add the basics ----
        for an in an_list:
            self.add_trial_dict_info(an, multi_an_sess, **kwargs)
            self.is_switch[an] = self.rzone_label[an]['set 0'] != self.rzone_label[an]['set 1']
            # copy place cell masks from multi_an_sess
            self.place_cell_masks[an]['set 0'] = np.copy(
                multi_an_sess[an]['pc masks set0'])
            self.place_cell_masks[an]['set 1'] = np.copy(
                multi_an_sess[an]['pc masks set1'])

            self.SI[an]['set 0'] = np.copy(
                multi_an_sess[an]['SI set0'])
            self.SI[an]['set 1'] = np.copy(
                multi_an_sess[an]['SI set1'])
            self.plane_per_cell[an] = multi_an_sess[an]['sess'].plane_per_cell
            if activity_criterion:
                self.apply_activity_criterion(an, multi_an_sess, **kwargs)

            self.add_activity_matrix(an, multi_an_sess, 
                                     use_speed_thr = self.use_speed_thr,
                                     speed_thr = self.speed_thr,
                                     ts_key=self.ts_key,
                                     )
            self.add_spatial_peaks(an, multi_an_sess, **kwargs)
            self.filter_cell_subset(an, multi_an_sess, **kwargs)

            
    def add_all_the_things(self, 
                           an_list, 
                           multi_an_sess, 
                           add_behavior=True, 
                           add_cell_classes=True,
                           add_circ_relative_peaks=True,
                           add_field_dict=True, **kwargs):
        
        for an in an_list:

            # find trials in each block
            self.blocks[an]['set 0']['tt'], self.blocks[an]['set 1']['tt'] = behav.find_trial_blocks(multi_an_sess[an],
                                                                                                     self.exp_day,
                                                                                                     define_blocks_by=self.def_block_by[
                                                                                                         an],
                                                                                                     block_len=10)
            # write block ID
            self.blocks[an]['set 0']['id'] = np.arange(
                len(self.blocks[an]['set 0']['tt'])).reshape(-1, 1)
            self.blocks[an]['set 1']['id'] = np.arange(
                len(self.blocks[an]['set 1']['tt'])).reshape(-1, 1)
            self.add_population_metrics(an, multi_an_sess, 
                                        smooth = self.smooth,
                                       sigma = self.sigma, 
                                       impute_nans = self.impute_NaNs,
                                       sim_method = self.sim_method,
                                        )

        #   Add behavior
            if add_behavior:
                self.add_lick_metrics(an, multi_an_sess, 
                                      lick_correction_thr = self.lick_correction_thr,
                                      )

            if add_field_dict:
                self.add_field_dict(an, multi_an_sess, **kwargs)

        if add_cell_classes:
            self.get_cell_classes(multi_an_sess, inc_dist=self.reward_dist_inclusive,
                                  ts_key=self.ts_key)
        if add_circ_relative_peaks:
            self.add_circ_relative_peaks(multi_an_sess, **kwargs)


# Class methods


    def add_trial_dict_info(self, an, multi_an_sess, **kwargs):

        trial_dict = behav.define_trial_subsets(
            multi_an_sess[an]['sess'], force_two_sets=self.force_two_sets
        )
        self.trial_dict[an] = trial_dict

        self.rzone_by_trial[an] = multi_an_sess[an]['rzone']
        self.rzone_pos[an]['set 0'] = np.unique(
            multi_an_sess[an]['rzone'][trial_dict['trial_set0']][0])
        if len(trial_dict['trial_set1']) > 0:
            self.rzone_pos[an]['set 1'] = np.unique(
                multi_an_sess[an]['rzone'][trial_dict['trial_set1']][0])
        else:
            self.rzone_pos[an]['set 1'] = self.rzone_pos[an]['set 0']

        self.rzone_label[an]['set 0'] = np.unique(
            multi_an_sess[an]['rz label'][trial_dict['trial_set0']][0])[0]
        if len(trial_dict['trial_set1']) > 0:
            self.rzone_label[an]['set 1'] = np.unique(
                multi_an_sess[an]['rz label'][trial_dict['trial_set1']][0])[0]
        else:
            self.rzone_label[an]['set 1'] = self.rzone_label[an]['set 0']

    def apply_activity_criterion(self, an, multi_an_sess,
                                 frac_trials_thr=0.25,
                                 field_thr=0.2,
                                 n_std=2,
                                 **kwargs):
        
        """
        Option to limit the set of included place cells to those which are active
        above a threshold in their place fields on a minimum percentage of trials
        """

        active_masks = {'set 0': [],
                        'set 1': []
                        }

        for s in ['0', '1']:
            tset = self.trial_dict[an]['trial_set' + s]
            tmp_masks = spatial.active_in_field(multi_an_sess[an]['sess'].trial_matrices['events'][0][tset, :, :],
                                                multi_an_sess[an]['sess'].trial_matrices['events'][-1],
                                                frac_trials_thr=frac_trials_thr,
                                                field_thr=field_thr,
                                                n_std=n_std,
                                                )
            active_masks['set ' + s] = tmp_masks

        print("%d original pcs" % np.logical_or(
            self.place_cell_masks[an]['set 0'], self.place_cell_masks[an]['set 1']).sum())

        self.place_cell_masks[an]['set 0'] = np.multiply(self.place_cell_masks[an]['set 0'],
                                                         active_masks['set 0']
                                                         )
        self.place_cell_masks[an]['set 1'] = np.multiply(self.place_cell_masks[an]['set 1'],
                                                         active_masks['set 1']
                                                         )
        print("%d active pcs" % np.logical_or(
            self.place_cell_masks[an]['set 0'], self.place_cell_masks[an]['set 1']).sum())
        

    def add_activity_matrix(self, an, multi_an_sess, use_speed_thr=False, speed_thr=2,
                            ts_key = 'dff', **kwargs):


        # recompute trial matrix using speed threshold if specified
        if use_speed_thr:
            speed = np.copy(multi_an_sess[an]['sess'].timeseries['speed'][0])
        else:
            speed = None

        start_pos = multi_an_sess[an]['sess'].trial_matrices[ts_key][-2][0]
        end_pos = multi_an_sess[an]['sess'].trial_matrices[ts_key][-2][-1]
        bin_size = end_pos / \
            len(multi_an_sess[an]['sess'].trial_matrices[ts_key][-1])

        tm = TwoPUtils.spatial_analyses.trial_matrix(multi_an_sess[an]['sess'].timeseries[ts_key].T,
                                                     multi_an_sess[an]['sess'].vr_data['pos']._values,
                                                     multi_an_sess[an]['sess'].trial_start_inds,
                                                     multi_an_sess[an]['sess'].teleport_inds,
                                                     bin_size=bin_size,
                                                     min_pos=start_pos,
                                                     max_pos=end_pos,
                                                     speed_thr=speed_thr,
                                                     speed=speed
                                                     )

        activity_mat = tm[0]

        self.activity_matrix[an] = activity_mat

        # copy the original events matrix
        self.events[an] = np.copy(multi_an_sess[an]['sess'].trial_matrices[
            'events'][0])
        self.pos_bin_centers[an] = tm[-1]

    def add_spatial_peaks(self, an, multi_an_sess,smooth=False, sigma=1, **kwargs):

        if len(self.activity_matrix[an]) == 0:
            raise NotImplementedError(
                "Activity matrix has not been calculated.")

        activity_mat = np.copy(self.activity_matrix[an])

        for s in ['0', '1']:
            if smooth:

                self.peaks[an]['set ' + s] = spatial.peak(
                    np.nanmean(
                        ut.nansmooth(
                            activity_mat[self.trial_dict[an]['trial_set'+s]], sigma, axis=1),
                        axis=0),
                    self.pos_bin_centers[an],
                    axis=0
                )
            else:
                self.peaks[an]['set ' + s] = spatial.peak(
                    np.nanmean(
                        activity_mat[self.trial_dict[an]['trial_set'+s]],
                        axis=0),
                    self.pos_bin_centers[an],
                    axis=0
                )

    def filter_cell_subset(self, an, multi_an_sess, **kwargs):

        if self.place_cell_logical == 'or':
            keep_masks = np.logical_or(
                self.place_cell_masks[an]['set 0'], self.place_cell_masks[an]['set 1'])
        elif self.place_cell_logical == 'and':
            keep_masks = np.logical_and(
                self.place_cell_masks[an]['set 0'], self.place_cell_masks[an]['set 1'])

        if self.exclude_int:
            self.is_int[an] = spatial.is_putative_interneuron(multi_an_sess[an]['sess'], ts_key='dff',
                                                              method=self.int_method, r_thresh=self.int_thresh)

            if len(self.is_int[an]) == 0:
                raise NotImplementedError("Ints have not been calculated.")
            keep_masks = np.multiply(keep_masks, ~self.is_int[an])

        # All "or" place cells excluding putative interneurons
        self.overall_place_cell_masks[an] = keep_masks

        if len(self.peaks[an]['set 0']) == 0:
            raise NotImplementedError(
                "Place field peaks have not been calculated.")

        # End cells: peak firing rate in first or last spatial bin
        end_cells = np.logical_or(
            np.logical_or(
                self.peaks[an]['set 0'] == self.pos_bin_centers[an][0],
                self.peaks[an]['set 0'] == self.pos_bin_centers[an][-1]),
            np.logical_or(
                self.peaks[an]['set 1'] == self.pos_bin_centers[an][0],
                self.peaks[an]['set 1'] == self.pos_bin_centers[an][-1])
        )
        self.is_end_cell[an] = end_cells

        # "Reward cells": peaks within 50 cm of both reward zone starts
        # use unsmoothed peak data
        reward_cells = spatial.find_reward_cells(self.peaks[an]['set 0'],
                                                 self.peaks[an]['set 1'],
                                                 self.rzone_pos[an]['set 0'][0],
                                                 self.rzone_pos[an]['set 1'][0],
                                                 reward_dist=self.reward_dist_exclusive)

        self.is_reward_cell[an] = reward_cells

        # "Track" cells: peaks within 50 cm of each other from set 0 to set 1,
        # [must also have significant spatial info in both sets]
        # excludes any that could also be counted as reward cells (useful for non-switch days)
        track_cells = spatial.find_track_cells(self.peaks[an]['set 0'],
                                                 self.peaks[an]['set 1'],
                                                 self.rzone_pos[an]['set 0'][0],
                                                 self.rzone_pos[an]['set 1'][0],
                                                 dist=self.reward_dist_exclusive)

        self.is_track_cell[an] = track_cells
        

    def get_cell_classes(self, multi_an_sess, inc_dist=50, ts_key='dff'):

        for an in self.anim_list:

            masks, fractions_total, fractions_placeor = spatial.get_cell_classes(
                multi_an_sess[an],
                self.peaks[an]['set 0'],
                self.peaks[an]['set 1'],
                self.is_int[an],
                inclusive_dist=inc_dist,
                ts_key=ts_key
            )

            self.cell_class[an]['masks'] = masks
            self.cell_class[an]['fractions_placeor'] = fractions_placeor
            self.cell_class[an]['fractions_total'] = fractions_total

    def add_population_metrics(self, an, multi_an_sess, reward_overrep_dist = 25, 
                               smooth = False,
                               sigma = 1, 
                               impute_nans = False,
                               sim_method = 'correlation',
                               **kwargs):
        """
        Run per animal

        Find 10-trial blocks within each larger trial set,
        compute place cell peak distributions, fraction of cells near reward,
        rate maps, and mean population vector similarity per block
        """
        pos = np.asarray(
            multi_an_sess[an]['sess'].trial_matrices[self.ts_key][-1])
        pos_edges = np.asarray(
            multi_an_sess[an]['sess'].trial_matrices['licks'][2])
        pos_bins = np.arange(
            0, pos_edges[-1]+self.bin_size, self.bin_size)

        ### Get trial x trial similarity ###
        # use events here for population vector corr
        activity_mat = np.copy(
            multi_an_sess[an]['sess'].trial_matrices['events'][0][:, :, self.overall_place_cell_masks[an]])
        lick_mat = np.copy(
            multi_an_sess[an]['sess'].trial_matrices['licks'][0])
        speed_mat = np.copy(
            multi_an_sess[an]['sess'].trial_matrices['speed'][0])

        if impute_nans:
            imputer = KNNImputer(n_neighbors=5)
            speed_mat = imputer.fit_transform(speed_mat)
            lick_mat = imputer.fit_transform(lick_mat)

        # smooth over position dim for correlations
        lick_mat = ut.nansmooth(
            lick_mat, sigma, axis=1, mode='nearest')
        speed_mat = ut.nansmooth(
            speed_mat, sigma, axis=1, mode='nearest')

        PV_mat = spatial.population_vector(ut.nansmooth(activity_mat,
                                                        sigma,
                                                        axis=1, mode='nearest'),
                                           axis=1)

        if sim_method == 'cosine_sim':
            self.sim_mat[an]['pv'] = spatial.cosine_similarity(
                PV_mat, zscore=False)
            self.sim_mat[an]['lick'] = spatial.cosine_similarity(
                lick_mat, zscore=False)
            self.sim_mat[an]['speed'] = spatial.cosine_similarity(
                speed_mat, zscore=False)
        elif sim_method == 'correlation':
            self.sim_mat[an]['pv'] = spatial.corr_mat(PV_mat)
            self.sim_mat[an]['lick'] = spatial.corr_mat(lick_mat)
            self.sim_mat[an]['speed'] = spatial.corr_mat(speed_mat)

        # use trial matrix specified in kwargs, and with speed threshold applied if specified
        if len(self.activity_matrix[an]) == 0:
            raise NotImplementedError(
                "Activity matrix has not been calculated.")
        activity_mat = np.copy(
            self.activity_matrix[an][:, :, self.overall_place_cell_masks[an]])

        if smooth:
            activity_mat = ut.nansmooth(
                activity_mat, sigma, axis=1, mode='nearest')

        # Get peak distributions, similarity, and fractions near reward by block
        for s in ['set 0', 'set 1']:
            if len(self.blocks[an][s]['id']) > 1:
                self.pc_distr[an][s] = {'mean': np.zeros((len(pos_bins)-1, 1))*np.nan,
                                        'by_block': np.zeros((len(self.blocks[an][s]['id']), len(pos_bins)-1))*np.nan}
                # fraction of cells w/in 50 cm of reward zone, per block
                self.rew_frac[an][s] = {'mean': np.zeros((len(pos_bins)-1, 1))*np.nan,
                                        'by_block': np.zeros((len(self.blocks[an][s]['id']), 1))*np.nan}

                # mean population activity in each spatial bin
                self.rate_map[an][s] = {'mean': np.zeros((len(pos_bins)-1, 1))*np.nan,
                                        'by_block': np.zeros((len(self.blocks[an][s]['id']), len(pos_bins)-1))*np.nan}
                # mean PV cosine similarity in each block
                self.pv_sim_mean[an][s] = {'mean': np.zeros((len(pos_bins)-1, 1))*np.nan,
                                           'by_block': np.zeros((len(self.blocks[an][s]['id']), 1))*np.nan}

                self.sim_to_set0[an][s] = {'by_block': np.zeros(
                    (len(self.blocks[an][s]['id']), 1))*np.nan}

                blockset_mat = np.concatenate(
                    [activity_mat[ts, :, :] for ts in self.blocks[an][s]['tt']], axis=0)  # trial_mat
                blockset_mean = np.nanmean(blockset_mat, axis=0)

                self.pc_distr[an][s]['mean'] = np.expand_dims(spatial.peak_hist_1d(blockset_mat,
                                                                                   pos,
                                                                                   bins=pos_bins,
                                                                                   smooth=False,
                                                                                   probability=True),
                                                              axis=1
                                                              )
                self.rate_map[an][s]['mean'] = np.nanmean(
                    blockset_mean, axis=1, keepdims=True)

                # Blocks for trial set 0
                for i, ts in enumerate(self.blocks[an][s]['tt']):
                    in_block = self.sim_mat[an]['pv'][ts, :][:, ts]
                    # get off-diagonal indices within block
                    off_diag = ~np.eye(in_block.shape[0], dtype=bool)
                    self.pv_sim_mean[an][s]['by_block'][i] = np.nanmean(
                        in_block[off_diag])

                    # correlation with the first block in set 0
                    self.sim_to_set0[an][s]['by_block'][i] = np.nanmean(
                        self.sim_mat[an]['pv'][self.blocks[an]['set 0']['tt'][0], :][:, ts].ravel())

                    # finding peaks on UNsmoothed ratemap
                    block_map = np.nanmean(
                        activity_mat[ts, :, :], axis=0)  # trial_mat
                    block_pks = spatial.peak(block_map, pos, axis=0)

                    self.pc_distr[an][s]['by_block'][i, :] = spatial.peak_hist_1d(activity_mat[ts, :, :],
                                                                                  pos,
                                                                                  bins=pos_bins,
                                                                                  smooth=False,
                                                                                  probability=True
                                                                                  )

                    self.rew_frac[an][s]['by_block'][i] = np.sum(
                        (np.abs(
                            block_pks - self.rzone_pos[an][s][0]) <= reward_overrep_dist)*1) / len(block_pks)

                    self.rate_map[an][s]['by_block'][i, :] = np.nanmean(
                        block_map, axis=1)  # average across cells

                # Get reward cell fraction on each trial
                if smooth:
                    find_trial_peaks = spatial.peak(ut.nansmooth(blockset_mat, sigma, axis=1),
                                                    coord=pos, axis=1)
                else:
                    find_trial_peaks = spatial.peak(blockset_mat,
                                                    pos, axis=1)
                self.rew_frac[an][s]['by_trial'] = np.sum(
                    (np.abs(find_trial_peaks - self.rzone_pos[an][s][0]) <= reward_overrep_dist)*1, axis=1
                ) / find_trial_peaks.shape[1]



    def add_lick_metrics(self, an, multi_an_sess, copy_orig_mat=False, 
                         lick_correction_thr=0.3, **kwargs):

        pos = self.pos_bin_centers[an]

        lickpos_std_ = behav.lick_pos_std(multi_an_sess[an]['sess'],
                                          correction_thr=lick_correction_thr,
                                          exclude_consum_licks=True)
        lickpos_com_ = behav.lickpos_com(multi_an_sess[an]['sess'],
                                         correction_thr=lick_correction_thr,
                                         exclude_consum_licks=True)

        if copy_orig_mat:
            self.orig_lick_mat = np.copy(
                multi_an_sess[an]['sess'].trial_matrices['licks'])

        self.lickpos_com[an]['set 0'] = lickpos_com_[
            self.trial_dict[an]['trial_set0']]
        self.lickpos_com[an]['set 1'] = lickpos_com_[
            self.trial_dict[an]['trial_set1']]
        self.lickpos_std[an]['set 0'] = lickpos_std_[
            self.trial_dict[an]['trial_set0']]
        self.lickpos_std[an]['set 1'] = lickpos_std_[
            self.trial_dict[an]['trial_set1']]

        for tt in [0, 1]:
            other = np.abs(tt-1)
            curr_trials = self.trial_dict[an]['trial_set' + str(tt)]
            other_trials = self.trial_dict[an]['trial_set' + str(other)]
            if len(curr_trials) > 0:
                lickdata = behav.calc_lick_metrics(multi_an_sess[an]['sess'],
                                                   curr_trials,
                                                   correct_sensor_error=True,
                                                   correction_thr=0.35,
                                                   permute_licks=False,
                                                   exclude_reward_zone=True,
                                                   exclude_consum_licks=True
                                                   )

                self.lick_mat[an]['set ' + str(tt)] = lickdata['lick_mat']

                curr_reward_zone = self.rzone_pos[an]['set ' + str(tt)]

                # for each trial
                self.curr_zone_lickrate[an]['set ' + str(tt)] = np.nanmean(
                    lickdata['lick_mat'][:, np.logical_and(
                        pos >= (curr_reward_zone[0] - 25), pos < curr_reward_zone[1])], axis=1)

                self.in_vs_out_lickratio[an]['set ' +
                                             str(tt)] = lickdata['trial_lick_ratio']

                # "other" zone not defined for the first day
                # if self.exp_day not in [0, 1, 2]:
                if self.trial_dict[an]['two_sets']:
                    other_reward_zone = self.rzone_pos[an]['set ' + str(other)]

                    self.other_zone_lickrate[an]['set ' + str(tt)] = np.nanmean(
                        lickdata['lick_mat'][:, np.logical_and(
                            pos >= (other_reward_zone[0] - 25), pos < other_reward_zone[1])], axis=1)

                    self.curr_vs_other_lickratio[an]['set ' + str(tt)] = (
                        (self.curr_zone_lickrate[an]['set ' + str(tt)] - self.other_zone_lickrate[an]['set ' + str(tt)]) /
                        (self.curr_zone_lickrate[an]['set ' + str(tt)] +
                            self.other_zone_lickrate[an]['set ' + str(tt)])
                    )
                else:
                    # check whether we have a previous day to compare to
                    # print(
                    #     "Only 1 set on this day; check previous day outside of dayData definition")
                    continue

    def add_field_dict(self, an, multi_an_sess, field_ts_key='events', **kwargs):

        field_dict = {"included cells": np.where(self.overall_place_cell_masks[an])[0],
                      'ts_key': field_ts_key,
                      'set 0': {}, 'set 1': {}}
        pos = self.pos_bin_centers[an]
        activity_map = {}
        for key in ['0', '1']:
            field_dict['set ' + key] = {
                "field COM": np.zeros((self.overall_place_cell_masks[an].sum(),))*np.nan,
                "field number": np.zeros((self.overall_place_cell_masks[an].sum(),))*np.nan,
                "field widths": {},
                "field pos": {},
            }

            activity_map[key] = np.nanmean(
                ut.nansmooth(
                    multi_an_sess[an]['sess'].trial_matrices[field_ts_key][0][
                        self.trial_dict[an]['trial_set'+key]
                    ], self.sigma, axis=1),
                axis=0)

            for pc_i, pc in enumerate(field_dict["included cells"]):

                data = activity_map[key][:, pc]
                field = spatial.field_from_thresh(data, pos, prctile=0.2)
                field_COM = ut.center_of_mass(
                    data[np.isin(pos,
                                 np.concatenate([f for f in field['pos'][0]])
                                 )],
                    coord=np.concatenate([f for f in field['pos'][0]]),
                    axis=0)
                # to not limit COM to the place fields:
                #         field_COM = ut.center_of_mass(data,coord=pos,axis=0)

                field_dict['set ' + key]['field pos'][pc] = field['pos'][0]
                field_dict['set ' +
                           key]['field widths'][pc] = field['widths'][0]
                field_dict['set ' +
                           key]['field number'][pc_i] = field['number'][0]
                field_dict['set ' + key]["field COM"][pc_i] = field_COM[0]

        self.field_dict[an] = field_dict

    def add_circ_relative_peaks(self, multi_an_sess, n_perm=1000,
                                max_pos=None,
                                min_pos=None,
                                circ_bins=None,
                                xcorr_thr=5,
                                **kwargs):

        from scipy.stats import vonmises


        # max and min pos should be in linear cm
        if max_pos is None:
            max_pos = multi_an_sess[self.anim_list[0]
                                    ]['sess'].trial_matrices['events'][2][-1]
        if min_pos is None:
            min_pos = multi_an_sess[self.anim_list[0]
                                    ]['sess'].trial_matrices['events'][2][0]

        # if a number of circular bins was not specified, compute it from the linear bins originally used
        if circ_bins is None:
            lin_bin_size = np.mean(
                np.diff(multi_an_sess[self.anim_list[0]]['sess'].trial_matrices['events'][2]))
            
            #check bin size
            circ_bins = ((max_pos-min_pos)/lin_bin_size)
            if (circ_bins % 1) != 0:
                raise NotImplementedError("Number of bins for circ trial matrix is not an integer -- check max position")

            # circ_bin_size = (2*np.pi)/circ_bins
            
            # I think this is a more stable way to space the bins:
            circ_bin_size = np.mean(np.ediff1d(np.linspace(-np.pi, np.pi, int(circ_bins))))
        else:
            # circ_bin_size = (2*np.pi)/circ_bins
            circ_bin_size = np.mean(np.ediff1d(np.linspace(-np.pi, np.pi, int(circ_bins))))

        # exclusive and inclusive dists around reward start, in radians
        rdist_to_rad_exc = circ.phase_diff(
            spatial.pos_cm_to_rad(
                self.reward_dist_exclusive, max_pos, min_pos=min_pos),
            spatial.pos_cm_to_rad(0, max_pos, min_pos=min_pos)
        )
        rdist_to_rad_inc = circ.phase_diff(
            spatial.pos_cm_to_rad(
                self.reward_dist_inclusive, max_pos, min_pos=min_pos),
            spatial.pos_cm_to_rad(0, max_pos, min_pos=min_pos)
        )


        for an_i, an in enumerate(self.anim_list):

            rzone0_start = self.rzone_pos[an]['set 0'][0]
            rzone1_start = self.rzone_pos[an]['set 1'][0]

            circ_rzone0 = spatial.pos_cm_to_rad(
                rzone0_start, max_pos, min_pos)
            circ_rzone1 = spatial.pos_cm_to_rad(
                rzone1_start, max_pos, min_pos)


            bin_edges = np.arange(-np.pi, np.pi+circ_bin_size, circ_bin_size)
            bin_centers = bin_edges[:-1]+circ_bin_size/2

            # circular position but NOT aligned to reward zone
            circ_pos = spatial.pos_cm_to_rad(
                multi_an_sess[an]['sess'].vr_data['pos'].values, max_pos, min_pos=min_pos)

            activity_ts = np.copy(
                multi_an_sess[an]['sess'].timeseries[self.ts_key].T)

            if self.use_speed_thr:
                speed = np.copy(multi_an_sess[an]
                                ['sess'].vr_data['speed'].values)
            else:
                speed = None

            # Make spatially-binned trial matrix for neural activity in circular coordinates
            circ_tm = TwoPUtils.spatial_analyses.trial_matrix(activity_ts,
                                                              circ_pos,
                                                              multi_an_sess[an]['sess'].trial_start_inds,
                                                              multi_an_sess[an]['sess'].teleport_inds,
                                                              bin_size=circ_bin_size,
                                                              min_pos=-np.pi,
                                                              max_pos=np.pi,
                                                              speed_thr=self.speed_thr,
                                                              speed=speed
                                                              )

            keep_masks = np.copy(self.overall_place_cell_masks[an])

            use_tm = circ_tm[0]

            # keep a copy of the circular trial matrix with all the cells
            self.circ_trial_matrix[an] = circ_tm

            # Get circularly-aligned licking and speed data
            licks = np.copy(multi_an_sess[an]['sess'].vr_data['lick'].values)
            lick_bin_size = np.copy(circ_bin_size)  # np.pi/24
            lick_bin_edges = np.arange(-np.pi, np.pi +
                                       lick_bin_size, lick_bin_size)

            speed_bin_size = np.pi/112
            speed_bin_edges = np.arange(-np.pi,
                                        np.pi+speed_bin_size, speed_bin_size)

            for t in ['0', '1']:
                if t == '0':
                    tmp_circ_pos = circ.wrap(circ_pos - circ_rzone0)

                else:
                    tmp_circ_pos = circ.wrap(circ_pos - circ_rzone1)
                trials = multi_an_sess[an]['trial dict']['trial_set' + t]
                _, _, lickmat = behav.lickrate_PETH(licks,
                                                    tmp_circ_pos,
                                                    lick_bin_edges,
                                                    multi_an_sess[an]['sess'].trial_start_inds,
                                                    multi_an_sess[an]['sess'].teleport_inds,
                                                    frame_time=behav.frametime(
                                                        multi_an_sess[an]['sess']),
                                                    trial_subset=trials,
                                                    correct_sensor_error=True,
                                                    correction_thr=self.lick_correction_thr,
                                                    zscore=False)
                self.circ_licks[an]['set '+t] = lickmat
                speed_tm = TwoPUtils.spatial_analyses.trial_matrix(multi_an_sess[an]['sess'].timeseries['speed'].T,
                                                                   tmp_circ_pos,
                                                                   multi_an_sess[an]['sess'].trial_start_inds[trials],
                                                                   multi_an_sess[an]['sess'].teleport_inds[trials],
                                                                   bin_size=speed_bin_size,
                                                                   min_pos=-np.pi,
                                                                   max_pos=np.pi,
                                                                   )
                self.circ_speed[an]['set '+t] = speed_tm

                self.circ_map[an].update(
                    {'set ' + t: use_tm[self.trial_dict[an]['trial_set'+t], :, :]})

            circ_peaks_0 = spatial.peak(np.nanmean(
                self.circ_map[an]['set 0'], axis=0),
                circ_tm[-1], axis=0)
            circ_peaks_1 = spatial.peak(np.nanmean(
                self.circ_map[an]['set 1'], axis=0),
                circ_tm[-1], axis=0)


            # self.keep_masks[an] = keep_masks

            circ_peaks_0 = circ_peaks_0[keep_masks]
            circ_peaks_1 = circ_peaks_1[keep_masks]

            rel_peaks0 = circ.wrap(circ_peaks_0 - circ_rzone0)
            rel_peaks1 = circ.wrap(circ_peaks_1 - circ_rzone1)

            # create null distribution of random remapping in set 1
            inds = np.where(keep_masks)[0]
            null = np.zeros((n_perm, len(inds)))
            rng = np.random.default_rng()
            map_to_shuf = np.nanmean(
                self.circ_map[an]['set 1'][:, :, keep_masks], axis=0).T
            for p in range(n_perm):

                # shuffle the actual map by a random number of bins between 0 and 44
                # and find new peaks, rather than generating random peaks
                for c in range(map_to_shuf.shape[0]):
                    this_shuf = np.roll(map_to_shuf[c, :], rng.integers(
                        0, map_to_shuf.shape[1]))  # , axis=1)
                    null[p, c] = spatial.peak(this_shuf,
                                              circ_tm[-1])

                # method to generate random peaks (also works equally well)
                # null[p, :] = circ_tm[-1][rng.integers(0,len(circ_tm[-1]),
                #                                            size=len(inds))]

            rel_null = circ.wrap(null - circ_rzone1)
            # subtract off the rel peak coord in set 0 to get the difference
            relrel_null = circ.wrap(rel_null - rel_peaks0)

            self.dist_btwn_rel_null[an] = relrel_null
            # subtract y-x to collapse points perpendicular to the y=1 diagonal,
            # to get the different in rew-relative distances between conditions
            self.dist_btwn_rel_peaks[an] = circ.wrap(rel_peaks1-rel_peaks0)

            hist_relrel_peaks, hist_relrel_null = _hist_dist_btwn_rel(self.dist_btwn_rel_peaks[an],
                                                                      relrel_null,
                                                                      bin_size=circ_bin_size,
                                                                      n_perm=n_perm)


            self.rel_peaks[an]['set 0'] = rel_peaks0
            self.rel_peaks[an]['set 1'] = rel_peaks1
            self.rel_null[an]['set 0'] = rel_peaks0
            self.rel_null[an]['set 1'] = rel_null

            # "distance along unity": circular mean of pre-switch and post-switch relative distance from reward
            kept_cells, self.reward_rel_dist_along_unity[an] = _mean_rel_dist(
                rel_peaks0, rel_peaks1, rdist_to_rad_inc)

            # store inds that are within dist_inc of the unity line
            # self.dist_along_unity_inds[an] = kept_cells  # boolean mask
            self.reward_rel_cell_ids[an] = np.where(
                keep_masks)[0][kept_cells]

            # Now further filter those to find reliable reward relative cells
            # Xcorr shuffle to check reward rel cells - perform xcorr for all cells
            _, xc_peaks_above_shuf = calc_field_xcorr(circ_tm, self.trial_dict[an],
                                                      rzone0_start, rzone1_start,
                                                      circ_rzone0, circ_rzone1,
                                                      n_perms=500, circ_shift=True,
                                                      cell_subset=None)

            # keep cells whose xc peak above the shuffle is <= xcorr_thr (5 bins) away from zero
            # currently assuming these are 10-cm bins
            self.xcorr_above_shuf[an] = xc_peaks_above_shuf
            reward_rel_above_shuf_bool = np.abs(xc_peaks_above_shuf)[
                self.reward_rel_cell_ids[an]] <= xcorr_thr
            self.reward_rel_cell_ids[an] = self.reward_rel_cell_ids[an][
                reward_rel_above_shuf_bool]

            # get circular mean distance along unity specifically for the kept RR cells
            self.reward_rel_dist_along_unity[an] = self.reward_rel_dist_along_unity[an][reward_rel_above_shuf_bool]


        # find animals with a reward switch
        is_reward_switch = [self.is_switch[key]
                            for key in self.is_switch.keys()]
        print(is_reward_switch)
        print(self.anim_list)

        include_ans = np.asarray(self.anim_list)[is_reward_switch]
        # leaving this in for now to ensure these animals don't get included
        include_ans = include_ans[~np.isin(
            include_ans, ['GCAMP2', 'GCAMP5', 'GCAMP6', 'GCAMP10'])]

        n_place_cells = np.sum(
            [np.sum(self.overall_place_cell_masks[an]) for an in include_ans])
       
        self.circ_rel_stats_across_an = {'include_ans': include_ans,
                                         'rdist_to_rad_inc': rdist_to_rad_inc,
                                         'rdist_to_rad_exc': rdist_to_rad_exc,
                                         'min_pos': min_pos,
                                         'max_pos': max_pos,
                                         'hist_bin_centers': bin_centers,
                                         
                                         }

    def filter_place_cells_posthoc(self,
                                   exclude_track_cells=False,
                                   exclude_reward_cells=False,
                                   exclude_end_cells=False,
                                   use_and_cells=False,
                                   ):
        """
        Filter place cell IDs to remove putative track-relative, putative reward, and/or end cells posthoc
        :return: bool_to_include - boolean of size self.overall_place_cell_masks[an].sum()
        """

        bool_to_include = {}
        inds_to_include = {}
        
        if use_and_cells:
            if self.place_cell_logical == 'and':
                print('Already using "and" place cells')
            else:
                print('Switching from "or" to "and" place cells')

        for an in self.anim_list:
                
            place_cell_ids = np.where(self.overall_place_cell_masks[an])[0]
            
            # default
            bool_to_include[an] = np.ones(place_cell_ids.shape).astype(bool)
            
            if use_and_cells:
                if self.place_cell_logical == 'or':
                    and_place_cell_ids = np.where(np.logical_and(
                                                        self.place_cell_masks[an]['set 0'],
                                                        self.place_cell_masks[an]['set 1'],
                                                    )
                                                 )[0]
                    # here we're selecting which cells to include from place_cell_ids
                    is_and = np.isin(place_cell_ids, and_place_cell_ids)
                    bool_to_include[an] = np.multiply(
                                bool_to_include[an], is_and)
                   
            # here we're selecting which cells to exclude from place_cell_ids
            if exclude_track_cells:
                track_cell_ids = np.where(self.is_track_cell[an])[0]
                not_track = ~np.isin(place_cell_ids, track_cell_ids)
                bool_to_include[an] = np.multiply(
                    bool_to_include[an], not_track)

            if exclude_reward_cells:
                reward_cell_ids = np.where(self.is_reward_cell[an])[0]
                not_near_reward = ~np.isin(place_cell_ids, reward_cell_ids)
                bool_to_include[an] = np.multiply(
                    bool_to_include[an], not_near_reward)

            if exclude_end_cells:
                end_cell_ids = np.where(self.is_end_cell[an])[0]
                not_end = ~np.isin(place_cell_ids, end_cell_ids)
                bool_to_include[an] = np.multiply(bool_to_include[an], not_end)

            inds_to_include[an] = place_cell_ids[bool_to_include[an]]

        return bool_to_include, inds_to_include

    
    
### Functions outside of class:

def find_common_anim(multiDayData, day_list=None):
    # find which animals are common to all days

    if day_list is None:
        day_list = multiDayData.keys()

    anim_each_day = [multiDayData[d].anim_list for d in day_list]

    common_anim = []
    for an in np.unique(np.concatenate(anim_each_day)):

        do_we_keep = np.all([np.isin(an, group) for group in anim_each_day])
        if do_we_keep:
            common_anim.append(an)

    common_anim = sorted(common_anim, key=len)
    print(f"keeping {common_anim}")

    return common_anim


def _mean_rel_dist(x, y, inc_dist):

    keep = circ.phase_diff(x, y) <= inc_dist

    mean_dist = astropy.stats.circmean(np.hstack((np.expand_dims(x[keep], 1),
                                                  np.expand_dims(y[keep], 1)
                                                  )),
                                       axis=1
                                       )
    return keep, mean_dist


def _hist_dist_btwn_rel(relrel_peaks, relrel_null, bin_size=(2*np.pi)/45,
                        n_perm=1000):

    bin_edges = np.arange(-np.pi, np.pi+bin_size, bin_size)
    hist_relrel_peaks, _ = np.histogram(relrel_peaks, bins=bin_edges)
    hist_relrel_peaks = hist_relrel_peaks / len(relrel_peaks)
    hist_relrel_null = np.zeros((n_perm, len(bin_edges)-1))
    for p in range(n_perm):
        hist_relrel_null[p, :], _ = np.histogram(
            relrel_null[p, :], bins=bin_edges)
        hist_relrel_null[p, :] = hist_relrel_null[p, :] / \
            len(relrel_peaks)

    return hist_relrel_peaks, hist_relrel_null


def _frac_hist_above_shuf(hist_relrel_peaks, hist_relrel_null, bin_centers, window=None):

    if window is not None:
        include_bins = (np.abs(bin_centers) <= window)
        frac = (hist_relrel_peaks[include_bins] - np.percentile(hist_relrel_null[:, include_bins], 95, axis=0))[
            (hist_relrel_peaks[include_bins] - np.percentile(
                hist_relrel_null[:, include_bins], 95, axis=0)) > 0
        ].sum()
    else:
        frac = (hist_relrel_peaks - np.percentile(hist_relrel_null, 95, axis=0))[
            (hist_relrel_peaks - np.percentile(
                hist_relrel_null, 95, axis=0)) > 0
        ].sum()
    return frac



def calc_field_xcorr(trial_mat, trial_dict,
                     rzone0, rzone1,
                     circ_rzone0, circ_rzone1,
                     n_perms=500, circ_shift=False,
                     cell_subset=None):
    """
    Calculate the xcorr between trial-averaged spatial activity
    in trial set 0 vs set 1, 
    and find the peak xcorr that exceeds 95% (the upper 97.5%) 
    of the shuffle distribution from circularly shuffling
    trials in set 1.

    cell_subset can be a boolean or list of indices

    circ_shift should be True to circularly align the reward zones
    across trial sets

    rzones are start coords only
    """
    lags = xc.xcorr_lags(len(trial_mat[-1]), len(trial_mat[-1]), mode="same")

    circ_bin_size = trial_mat[-2][-1] - trial_mat[-2][-2]

    if cell_subset is not None:
        set0_map = trial_mat[0][trial_dict['trial_set0'],
                                :, :][:, :, cell_subset]
        set1_map = trial_mat[0][trial_dict['trial_set1'],
                                :, :][:, :, cell_subset]
    else:
        set0_map = trial_mat[0][trial_dict['trial_set0'], :, :]
        set1_map = trial_mat[0][trial_dict['trial_set1'], :, :]

    xc_peaks_above_shuf = np.zeros((set0_map.shape[2],))*np.nan

    if circ_shift:
        # find the number of indices that aligns rzone1 with rzone 1
        if rzone0 > rzone1:
            shift = int(np.round((circ_rzone0-circ_rzone1)/circ_bin_size))
        elif rzone1 > rzone0:
            shift = -int(np.round((circ_rzone1-circ_rzone0)/circ_bin_size))
        else:
            shift = 0

        if shift != 0:
            set1_map = np.roll(
                set1_map,
                shift,
                axis=1
            )

    def shuffle_xcorr(cell_map0, cell_map1, lags):

        # trial_avg map
        this_cell_map0 = np.nanmean(cell_map0, axis=0)
        this_cell_map1 = np.nanmean(cell_map1, axis=0)

        xc_vec = sp.signal.correlate(ut.zscore(this_cell_map0),
                                     ut.zscore(this_cell_map1), mode="same") / (len(ut.zscore(this_cell_map0))-1)

        xc_peaks = lags[ut.nanargmax(xc_vec)]

        xc_mat_perm = np.zeros((n_perms, len(lags)))*np.nan
        for perm in range(n_perms):
            tmp_map = np.copy(cell_map1)
            for t in range(cell_map1.shape[0]):
                tmp_map[t, :] = np.roll(
                    tmp_map[t, :], np.random.randint(1, high=cell_map1.shape[1]))

            tmp_map = np.nanmean(tmp_map, axis=0)

            xc_mat_perm[perm, :] = sp.signal.correlate(ut.zscore(this_cell_map0),
                                                       ut.zscore(tmp_map),
                                                       mode="same") / (len(ut.zscore(this_cell_map0))-1)

        xc_shuf_mean = np.nanmean(xc_mat_perm, axis=0)
        xc_shuf_CI_low = np.percentile(xc_mat_perm, 2.5, axis=0)
        xc_shuf_CI_hi = np.percentile(xc_mat_perm, 97.5, axis=0)

        above_shuf = xc_vec > xc_shuf_CI_hi
        if np.any(above_shuf):
            xc_peaks_above_shuf_tmp = lags[above_shuf][
                ut.nanargmax(xc_vec[above_shuf])]
        else:
            xc_peaks_above_shuf_tmp = np.nan

        xc_shuf = {'mean': xc_shuf_mean,
                   'CI_lo': xc_shuf_CI_low, 'CI_hi': xc_shuf_CI_hi}
        return xc_vec, xc_shuf, xc_peaks, xc_peaks_above_shuf_tmp

    delayed_results = [dask.delayed(shuffle_xcorr)(
        set0_map[:, :, cell], set1_map[:, :, cell], lags) for cell in tqdm(range(set0_map.shape[2]))]

    with ProgressBar():
        results = dask.compute(delayed_results, scheduler='processes')

    for c in range(len(results[0])):
        xc_peaks_above_shuf[c] = results[0][c][-1]

    return results, xc_peaks_above_shuf


def dayData_to_df(multiDayData, columns, anim_list=None, manual_dict = None):
    """
    Convert multiDayData dictionary to pandas DataFrame
    Columns 'mouse' and 'day' are added by default; 
    arg input column names should match fields of dayData
    """

    import pandas as pd

    col = ['mouse', 'day', 'switch', 'env']
    [col.append(c) for c in columns]

    df = pd.DataFrame(columns=col)

    day_list = multiDayData.keys()
    experiment = multiDayData[list(multiDayData.keys())[0]].experiment


    for d_i, day in enumerate(day_list):
        if anim_list is None:
            anim_list = multiDayData[d].anim_list

        for an in anim_list:
            # check if animal entry is a dict (likely, 'set 0', 'set 1'):
            if manual_dict is None:
                if (type(getattr(multiDayData[day], columns[0])[an]) is dict):
                    raise NotImplementedError("Entry is a dict, expected array")
                # check if lengths of all column arrays are equal
                try:
                    array_len = [len(getattr(multiDayData[day], cc)[an])
                                 for cc in columns]
                except:
                    array_len = [len([getattr(multiDayData[day], cc)[an]])
                                 for cc in columns]
            else:
                array_len = [len([manual_dict[cc][day][an]])
                                 for cc in columns]
                
            if np.diff(array_len).sum() != 0:
                raise NotImplementedError("Expected equal array lengths")

            n_entries = array_len[0]
            mouse_arr = np.repeat(an, n_entries)
            day_arr = np.repeat(day, n_entries)

            if experiment == 'MetaLearn':
                if day in [3, 5, 7]:
                    if an in ['GCAMP17', 'GCAMP18']:
                        env = int(1)
                    else:
                        env = int(0)
                elif day == 8:
                    env = 'change env'
                elif day in [10, 12, 14]:
                    if an in ['GCAMP17', 'GCAMP18']:
                        env = int(0)
                    else:
                        env = int(1)
            elif experiment == 'NeuroMods':
                if day < 10:
                    env = int(0)
                elif day in [10, 12, 14]:
                    env = int(1)
                elif day in [15, 17]:
                    env = int(2)
            else:
                env = np.nan

            env_arr = np.repeat(env, n_entries)
            #switch = np.argwhere(switch_list==day)
            # print(day, switch)
            switch_arr = np.repeat(d_i, n_entries).astype(float)  # update this

            col_data = {}

            df_this_day = pd.DataFrame({'mouse': mouse_arr,
                                        'day': day_arr,
                                        'switch': switch_arr,
                                        'env': env_arr}
                                       )
            
            for cc in columns:
                if manual_dict is not None:
                    df_this_day[cc] = manual_dict[cc][day][an]
                else:
                    df_this_day[cc] = getattr(multiDayData[day], cc)[an]

            df = df.append(df_this_day,
                           ignore_index=True)
    return df


# Plotting across days -----------
def plot_rew_rel_hist_across_an(multiDayData,
                                bin_size=(2*np.pi)/45,
                                dot_edges='on',
                                exclude_reward_cells=False,
                                exclude_track_cells=True,
                                exclude_end_cells=False,
                                use_and_cells=True,
                                max_pos=450,
                                min_pos=0,
                                return_frac_above_shuf=False,
                               return_dist_along_unity=False):
    """
    Plot histogram of distance between reward-relative peaks, compared to shuffle.
    Also calculates the fraction above shuffle (with specified cell types excluded
    from the shuffle) and adds this as an attribute to multiDayData[day]

    """
    from matplotlib import pyplot as plt
    from matplotlib.ticker import MaxNLocator
    from . import plotUtils as pt
    from pycircstat import tests as circ_tests
    from pycircstat.descriptive import median as circ_median

    exp_days = multiDayData.keys()
    if len(exp_days) == 1:
        fig1, ax1 = plt.subplots(
            len(exp_days)+1, 2, figsize=(8, 1.75*len(exp_days)))
        fig2, ax2 = plt.subplots(
            len(exp_days)+1, 1, figsize=(5, 4*len(exp_days)))
    else:
        fig1, ax1 = plt.subplots(
            len(exp_days), 2, figsize=(8, 1.75*len(exp_days)))
        fig2, ax2 = plt.subplots(
            len(exp_days), 1, figsize=(5, 4*len(exp_days)))

    bin_edges = np.arange(-np.pi, np.pi+bin_size, bin_size)
    bin_centers = bin_edges[:-1]+bin_size/2
    rzone = spatial.pos_cm_to_rad(50, max_pos, min_pos) - bin_edges[0]

    frac_above_shuf = {}

    for d_i, day in enumerate(exp_days):

        rdist_to_rad_exc = multiDayData[day].circ_rel_stats_across_an['rdist_to_rad_exc']
        rdist_to_rad_inc = multiDayData[day].circ_rel_stats_across_an['rdist_to_rad_inc']
        include_ans = multiDayData[day].circ_rel_stats_across_an["include_ans"]

        # Concatenate relative peaks
        dist_btwn_rel_peaks = {}
        rel_peaks0 = {}
        rel_peaks1 = {}
        dist_btwn_rel_null = {}


        include_ans = multiDayData[day].circ_rel_stats_across_an["include_ans"]

        # Filter and concatenate relative peaks

        bool_to_include, inds_to_include = multiDayData[day].filter_place_cells_posthoc(
            exclude_track_cells=exclude_track_cells,
            exclude_reward_cells=exclude_reward_cells,
            exclude_end_cells=exclude_end_cells,
            use_and_cells=use_and_cells,
        )

        for an in include_ans:

            dist_btwn_rel_peaks[an] = multiDayData[day].dist_btwn_rel_peaks[an][bool_to_include[an]]
            rel_peaks0[an] = multiDayData[day].rel_peaks[an]['set 0'][bool_to_include[an]]
            rel_peaks1[an] = multiDayData[day].rel_peaks[an]['set 1'][bool_to_include[an]]
            dist_btwn_rel_null[an] = multiDayData[day].dist_btwn_rel_null[an][:,
                                                                              bool_to_include[an]]

        use_rel_dist = np.hstack(
            [dist_btwn_rel_peaks[an] for an in include_ans])
        use_rel_peaks_set0 = np.hstack(
            [rel_peaks0[an] for an in include_ans])
        use_rel_peaks_set1 = np.hstack(
            [rel_peaks1[an] for an in include_ans])

        use_rel_dist_null = np.hstack([dist_btwn_rel_null[an]
                                       for an in include_ans])


        hist_data, hist_null = _hist_dist_btwn_rel(
            use_rel_dist,
            use_rel_dist_null,
            bin_size=bin_size
        )
        use_hist_rel_dist_null = hist_null

        use_frac_above_shuf = _frac_hist_above_shuf(hist_data, hist_null, bin_centers,
                                                    window=rdist_to_rad_exc)

        use_dist_along_unity_inds, use_dist_along_unity = _mean_rel_dist(
            use_rel_peaks_set0, use_rel_peaks_set1, rdist_to_rad_inc)


        frac_above_shuf[day] = use_frac_above_shuf

        ax1[d_i, 0].set_title("day %d, switch %d" % (day, d_i), fontsize=10)
        ax1[d_i, 0].plot(bin_centers,
                         np.nanmean(use_hist_rel_dist_null,
                                    axis=0), linewidth=2, color='r')
        ax1[d_i, 0].plot(bin_centers,
                         np.percentile(use_hist_rel_dist_null,
                                       95,
                                       axis=0), '--', color='r')

        hist_rel, _ = pt.histogram(use_rel_dist,
                                   ax=ax1[d_i, 0], bins=bin_edges, plot=True, facecolor='black',
                                   edgecolor='black',
                                   label="n=%d" % (
                                       len(
                                           use_rel_dist),  
                                   )
                                   )
        
        ## Write histogram to the class, with params:
        multiDayData[day].circ_rel_stats_across_an['hist_dist_btwn_rel_peaks'] = hist_data
        multiDayData[day].circ_rel_stats_across_an['hist_null'] = hist_null
        multiDayData[day].circ_rel_stats_across_an.update({'hist_params': {'exclude_track_cells': exclude_track_cells,
                                                                           'exclude_reward_cells':exclude_reward_cells,
                                                                            'exclude_end_cells':exclude_end_cells,
                                                                            'use_and_cells':use_and_cells,
                                                                          }
                                                          })
                                                                           

        ax1[d_i, 0].set_xlabel('dist. between rel. peaks (rad)')
        ax1[d_i, 0].set_ylabel('fraction of cells')
        ax1[d_i, 0].legend()

        ax1[d_i, 1].fill_betweenx([0, 0.05], [0, 0], [rzone, rzone],
                                  color=(0, 0.8, 1, 0.3))

        hist_unity, _ = np.histogram(use_dist_along_unity,
                                     bins=bin_edges)

        cmean = circ_tests.mtest(use_dist_along_unity, 0)[1]
        # lower and upper CI
        cmean_lo = circ_tests.mtest(use_dist_along_unity, 0)[-1][0]
        cmean_hi = circ_tests.mtest(use_dist_along_unity, 0)[-1][1]
        # med_pval = circ_tests.medtest(use_dist_along_unity, 0)[0]
        cmean_H = circ_tests.mtest(use_dist_along_unity, 0)[0]
        # normalize to place cells included in the scatter
        hist_unity = hist_unity/len(use_rel_dist)

        ax1[d_i, 1].hist(bin_edges[:-1], bin_edges,
                         weights=hist_unity,
                         facecolor='orange',
                         edgecolor='orange',
                         alpha=1,
                         # label = "n=%d \n med = %.3f, \n p = %.3e" % (
                         label="n=%d \n var %.3f" % (
            len(use_dist_along_unity),
                             astropy.stats.circstats.circvar(
                use_dist_along_unity)
            
        ))
        ax1[d_i, 1].vlines(cmean, 0,
                           ax1[d_i, 1].get_ylim()[-1], color='k', linestyle=':',
                           label= "mean %.3f, \n CI=[%.3f, %.3f], \n nonzero_p = %s" % (
            cmean,
            cmean_lo,
            cmean_hi,
            cmean_H[0])                   
        )

        ax1[d_i, 1].set_xlabel('dist from joint peak to reward (rad)')
        ax1[d_i, 1].set_ylabel('fraction of cells')
        ax1[d_i, 1].vlines(-rdist_to_rad_exc, 0,
                           ax1[d_i, 1].get_ylim()[-1], color='m', linestyle='--')
        ax1[d_i, 1].vlines(rdist_to_rad_exc, 0,
                           ax1[d_i, 1].get_ylim()[-1], color='m', linestyle='--', label="50 cm")
        ax1[d_i, 0].set_xticks([-3, -2, -1, 0, 1, 2, 3])
        ax1[d_i, 1].set_xticks([-3, -2, -1, 0, 1, 2, 3])
        ax1[d_i, 1].legend(loc='upper left', bbox_to_anchor=(1.05, 1.05))

        # Scatter - if /50, jitter between -np.pi/100 and np.pi/100
        ax2[d_i].plot([-np.pi, np.pi], [-np.pi, np.pi],
                      '--', color='grey', alpha=0.7)
        jitter0 = (np.random.random_sample(
            len(use_rel_peaks_set0
                )) - 0.5) * (np.pi/50) #if /25, then jitter up tp pi/50
        jitter1 = (np.random.random_sample(
            len(use_rel_peaks_set1
                )) - 0.5) * (np.pi/50)

        xx = np.arange(-np.pi+multiDayData[day].circ_rel_stats_across_an['rdist_to_rad_inc'],
                       np.pi -
                       multiDayData[day].circ_rel_stats_across_an['rdist_to_rad_inc'],
                       bin_size)
        y1 = xx + \
            multiDayData[day].circ_rel_stats_across_an['rdist_to_rad_inc']
        y2 = xx - \
            multiDayData[day].circ_rel_stats_across_an['rdist_to_rad_inc']
        ax2[d_i].fill_between(xx,
                              y1,
                              y2,
                              facecolor='orange',
                              alpha=0.3)

        black0 = (use_rel_peaks_set0 + jitter0)[
            ~use_dist_along_unity_inds
        ]
        black1 = (use_rel_peaks_set1 + jitter1)[
            ~use_dist_along_unity_inds
        ]
        ss = ax2[d_i].scatter(black0,
                              black1,
                              20,
                              color='k',
                              edgecolors='none',
                              alpha=0.5)

        orange0 = (use_rel_peaks_set0 + jitter0)[
            use_dist_along_unity_inds
        ]
        orange1 = (use_rel_peaks_set1 + jitter1)[
            use_dist_along_unity_inds
        ]
        if dot_edges == 'on':
            ax2[d_i].scatter(orange0,
                             orange1,
                             20,
                             color='black',
                             edgecolors='orange',
                             linewidths=0.5,
                             alpha=0.5
                             )
        else:
            ax2[d_i].scatter(orange0,
                             orange1,
                             20,
                             color='black',
                             edgecolors='none',
                             alpha=0.5
                             )

        ax2[d_i].set_title("day %d, switch %d" % (day, d_i), fontsize=10)
        ax2[d_i].vlines(0, -np.pi, np.pi, color='k')
        ax2[d_i].vlines(-rdist_to_rad_exc, -rdist_to_rad_exc,
                        rdist_to_rad_exc, color='m')
        ax2[d_i].vlines(rdist_to_rad_exc, -rdist_to_rad_exc,
                        rdist_to_rad_exc, color='m')
        ax2[d_i].hlines(-rdist_to_rad_exc, -rdist_to_rad_exc,
                        rdist_to_rad_exc, color='m')
        ax2[d_i].hlines(rdist_to_rad_exc, -rdist_to_rad_exc,
                        rdist_to_rad_exc, color='m')
        ax2[d_i].hlines(0, -np.pi, np.pi, color='k')

        ax2[d_i].set_xticks([-3, -2, -1, 0, 1, 2, 3])
        # ax2[d_i].set_xticklabels([-3,-2,-1,0,1,2,3])
        ax2[d_i].set_xlabel('peak relative to reward (rad), before')
        ax2[d_i].set_ylabel('peak relative to reward (rad), after')

        ax2[d_i].axis('square')
        # ax2[d_i].set_ylim([-np.pi, np.pi])
        # ax2[d_i].set_xlim([-np.pi, np.pi])

    [ax1[d_i, 0].set_ylim([0, np.max([ax1[d, 0].get_ylim() for d in range(len(exp_days))])])
     for d_i in range(len(exp_days))]

    [ax1[d_i, 0].yaxis.set_major_locator(MaxNLocator(
        integer=False, min_n_ticks=4)) for d_i in range(len(exp_days))]

    [ax1[d_i, 1].set_ylim([0, np.max([ax1[d, 1].get_ylim() for d in range(len(exp_days))])])
     for d_i in range(len(exp_days))]

    if return_frac_above_shuf and not return_dist_along_unity:
        return fig1, fig2, frac_above_shuf
    elif return_dist_along_unity and return_frac_above_shuf:
        return fig1, fig2, frac_above_shuf, use_dist_along_unity
    else:
        return fig1, fig2


def plot_rew_rel_hist_indiv_an(multiDayData,
                               exclude_reward_cells=False,
                               exclude_track_cells=True,
                               exclude_end_cells=False,
                               use_and_cells=True,
                               ylim_max=None,
                               return_frac_above_shuf=False,
                               return_dist_along_unity=False,
                               bin_size=(2*np.pi)/45):
    """
    Plot histogram of distance between reward-relative peaks, compared to shuffle
    For INDIVIDUAL animals
    """
    from matplotlib import pyplot as plt
    from . import plotUtils as pt

    exp_days = multiDayData.keys()
    max_include_ans = sorted(
        np.unique(np.concatenate(
            [multiDayData[d].circ_rel_stats_across_an["include_ans"]
                for d in exp_days]
        )), key=len)

    if len(exp_days) == 1:
        rows = len(exp_days)+1
    else:
        rows = len(exp_days)

    fig1, ax1 = plt.subplots(rows, len(max_include_ans),
                             figsize=(3*len(max_include_ans), 2*len(exp_days)),
                             sharey=True)
    fig2, ax2 = plt.subplots(rows, len(max_include_ans),
                             figsize=(3*len(max_include_ans), 2*len(exp_days)),
                             sharey=True)
    fig3, ax3 = plt.subplots(rows, len(max_include_ans),
                             figsize=(5*len(max_include_ans), 4*len(exp_days)))

    bin_edges = np.arange(-np.pi, np.pi+bin_size, bin_size)
    bin_centers = bin_edges[:-1]+bin_size/2

    frac_above_shuf = {}
    dist_along_unity = {}

    for d_i, day in enumerate(exp_days):
        rdist_to_rad_exc = multiDayData[day].circ_rel_stats_across_an['rdist_to_rad_exc']
        frac_above_shuf[day] = dict([(an, {}) for an in max_include_ans])
        
        bool_to_include, inds_to_include = multiDayData[day].filter_place_cells_posthoc(
            exclude_track_cells=exclude_track_cells,
            exclude_reward_cells=exclude_reward_cells,
            exclude_end_cells=exclude_end_cells,
            use_and_cells=use_and_cells,
        )
        
        dist_btwn_rel_peaks = {}
        rel_peaks0 = {}
        rel_peaks1 = {}
        dist_btwn_rel_null = {}
        dist_along_unity[day] = {}
        
        for an_i, an in enumerate(max_include_ans):
            if an in multiDayData[day].dist_btwn_rel_peaks.keys():

                dist_btwn_rel_peaks[an] = multiDayData[day].dist_btwn_rel_peaks[an][bool_to_include[an]]
                rel_peaks0[an] = multiDayData[day].rel_peaks[an]['set 0'][bool_to_include[an]]
                rel_peaks1[an] = multiDayData[day].rel_peaks[an]['set 1'][bool_to_include[an]]
                dist_btwn_rel_null[an] = multiDayData[day].dist_btwn_rel_null[an][:,
                                                                                  bool_to_include[an]]
            
                hist_data, hist_null = _hist_dist_btwn_rel(
                    dist_btwn_rel_peaks[an],
                    dist_btwn_rel_null[an],
                    bin_size=bin_size
                )
                ax1[d_i, an_i].plot(bin_centers,
                                    np.nanmean(hist_null,
                                               axis=0), linewidth=2, color='r')
                ax1[d_i, an_i].plot(bin_centers,
                                    np.percentile(hist_null,
                                                  95,
                                                  axis=0), '--', color='r')

                frac_above_shuf[day][an] = _frac_hist_above_shuf(hist_data, hist_null, bin_centers,
                                                                 window=rdist_to_rad_exc)  

                ax1[d_i, an_i].hist(bin_edges[:-1], bin_edges,
                                    weights=hist_data,
                                    facecolor='black',
                                    edgecolor='black',
                                    label="n=%d, \n frac above shuf=%.2f" % (
                    len(
                        dist_btwn_rel_peaks[an]),
                    frac_above_shuf[day][an]
                )
                )
                ax1[d_i, an_i].set_xlabel('dist. between rel. peaks (rad)')
                ax1[d_i, an_i].set_ylabel('fraction of cells')
                ax1[d_i, an_i].legend()
                
                use_dist_along_unity_inds, use_dist_along_unity = _mean_rel_dist(
                    rel_peaks0[an], 
                    rel_peaks1[an],
                    multiDayData[day].circ_rel_stats_across_an['rdist_to_rad_inc'])

                dist_along_unity[day][an] = use_dist_along_unity

                hist_dist_along_unity, _ = np.histogram(
                    use_dist_along_unity, bins=bin_edges)
                # normalized to the number of reward-relative cells here
                hist_dist_along_unity = hist_dist_along_unity / \
                    len(use_dist_along_unity)
                ax2[d_i, an_i].hist(bin_edges[:-1], bin_edges,
                                    weights=hist_dist_along_unity,
                                    facecolor='orange',
                                    edgecolor='orange',
                                    alpha=0.5,
                                    label="RR n=%d \n var %.3f, mean = %.3f" % (
                    len(use_dist_along_unity),
                    astropy.stats.circstats.circvar(
                        use_dist_along_unity),
                    astropy.stats.circstats.circmean(use_dist_along_unity))
                )
                ax2[d_i, an_i].set_xlabel(
                    'dist from joint peak to reward (rad)')
                ax2[d_i, an_i].set_ylabel('fraction of cells')
                ax2[d_i, an_i].vlines(-rdist_to_rad_exc, 0,
                                      ax2[d_i, an_i].get_ylim()[-1], color='m', linestyle='--')
                ax2[d_i, an_i].vlines(rdist_to_rad_exc, 0,
                                      ax2[d_i, an_i].get_ylim()[-1], color='m', linestyle='--')
                ax2[d_i, an_i].legend()

                # Scatter
                ax3[d_i, an_i].plot([-np.pi, np.pi], [-np.pi, np.pi],
                                    '--', color='grey', alpha=0.7)
                jitter0 = (np.random.random_sample(
                    len(rel_peaks0[an]
                        )) - 0.5) * (np.pi/50)
                jitter1 = (np.random.random_sample(
                    len(rel_peaks1[an]
                        )) - 0.5) * (np.pi/50)

                black0 = (rel_peaks0[an] + jitter0)[
                    ~use_dist_along_unity_inds
                ]
                black1 = (rel_peaks1[an] + jitter1)[
                    ~use_dist_along_unity_inds
                ]
                ss = ax3[d_i, an_i].scatter(black0,
                                            black1,
                                            20,
                                            color='k',
                                            edgecolors='none',
                                            alpha=0.5)

                orange0 = (rel_peaks0[an] + jitter0)[
                    use_dist_along_unity_inds
                ]
                orange1 = (rel_peaks1[an] + jitter1)[
                    use_dist_along_unity_inds
                ]
                ax3[d_i, an_i].scatter(orange0,
                                       orange1,
                                       20,
                                       color='black',
                                       edgecolors='orange',
                                       linewidths=0.5,
                                       alpha=0.5
                                       )

                ax3[d_i, an_i].vlines(0, -np.pi, np.pi, color='k')
                ax3[d_i, an_i].vlines(-rdist_to_rad_exc, -rdist_to_rad_exc,
                                      rdist_to_rad_exc, color='m')
                ax3[d_i, an_i].vlines(rdist_to_rad_exc, -rdist_to_rad_exc,
                                      rdist_to_rad_exc, color='m')
                ax3[d_i, an_i].hlines(-rdist_to_rad_exc, -rdist_to_rad_exc,
                                      rdist_to_rad_exc, color='m')
                ax3[d_i, an_i].hlines(rdist_to_rad_exc, -rdist_to_rad_exc,
                                      rdist_to_rad_exc, color='m')
                ax3[d_i, an_i].hlines(0, -np.pi, np.pi, color='k')
                ax3[d_i, an_i].axis('square')
                ax3[d_i, an_i].set_xlabel(
                    'peak relative to reward (rad), before')
                ax3[d_i, an_i].set_ylabel(
                    'peak relative to reward (rad), after')

        if ylim_max is None:
            [[ax1[d_i, an_i].set_ylim([0, np.max([ax1[d, an_i].get_ylim() for d in range(len(exp_days))])])
              for d_i in range(len(exp_days))] for an_i in range(len(max_include_ans))]

            [[ax2[d_i, an_i].set_ylim([0, np.max([ax2[d, an_i].get_ylim() for d in range(len(exp_days))])])
              for d_i in range(len(exp_days))] for an_i in range(len(max_include_ans))]
        else:
            [[ax1[d_i, an_i].set_ylim([0, ylim_max[0]])
              for d_i in range(len(exp_days))] for an_i in range(len(max_include_ans))]

            [[ax2[d_i, an_i].set_ylim([0, ylim_max[1]])
              for d_i in range(len(exp_days))] for an_i in range(len(max_include_ans))]

        [ax1[0, an_i].set_title(an) for an_i, an in enumerate(max_include_ans)]
        [ax2[0, an_i].set_title(an) for an_i, an in enumerate(max_include_ans)]

    if return_frac_above_shuf and not return_dist_along_unity:
        return fig1, fig2, fig3, frac_above_shuf
    elif return_frac_above_shuf and return_dist_along_unity:
        return fig1, fig2, frac_above_shuf, use_dist_along_unity
    else:
        return fig1, fig2, fig3


def subclass(_multiDayData):
    import copy

    class dayDataReduced:

        def __init__(self, _dayData):

            self.reward_rel_cell_ids = copy.deepcopy(getattr(_dayData,
                                                             'reward_rel_cell_ids'))
            self.cell_class = copy.deepcopy(getattr(_dayData,
                                                    'cell_class'))

            self.circ_rel_stats_across_an = copy.deepcopy(getattr(_dayData,
                                                                  'circ_rel_stats_across_an'))

            self.overall_place_cell_masks = copy.deepcopy(getattr(_dayData,
                                                                  'overall_place_cell_masks'))

    multiDayDataSub = {}

    for day in _multiDayData.keys():

        multiDayDataSub[day] = dayDataReduced(_multiDayData[day])

    return multiDayDataSub


def get_cell_class_n(_multiDayData, day, an, exclude_rr_from_others=True, verbose=True):
    
    celltype_list = ['rr','track', 'disappear', 'appear', 'reward','nonreward_remap']
    
    n_out = {}
    inds = {}
    
    
    def _exclude_rr(_inds, category, verbose=True):
        is_rr = np.isin(
                _inds, _multiDayData[day].reward_rel_cell_ids[an])
        if verbose:
            print(f"excluding {is_rr.sum()} from {len(_inds)} {category}")
        inds_to_keep = _inds[~is_rr]
        return inds_to_keep
        
    
    for celltype in celltype_list:
        if celltype == 'rr':
            keep = _multiDayData[day].reward_rel_cell_ids[an]
            n_out['rr'] = len(keep)
            inds['rr'] = keep

        elif celltype == 'track':
            keep = np.where(
                _multiDayData[day].cell_class[an]['masks']['track'])[0]

        elif celltype == 'appear':
            keep = np.where(
                _multiDayData[day].cell_class[an]['masks']['appear'])[0]

        elif celltype == 'disappear':
            keep = np.where(
                _multiDayData[day].cell_class[an]['masks']['disappear'])[0]
            
        elif celltype == 'nonreward_remap':
            keep = np.where(
                _multiDayData[day].cell_class[an]['masks']['nonreward_remap'])[0]
            n_out['nonreward_remap_inc_rr'] = len(keep)
            inds['nonreward_remap_inc_rr'] = keep

        elif celltype == 'non-track':
            keep = np.where((_multiDayData[day].cell_class[an]['masks']['appear'] |
                             _multiDayData[day].cell_class[an]['masks']['disappear'] |
                             _multiDayData[day].cell_class[an]['masks']['nonreward_remap']
                             ))[0]
        elif celltype == 'reward':
            keep = np.where(
                _multiDayData[day].cell_class[an]['masks']['reward'])[0]
            n_out['reward_inc_rr'] = len(keep)
            inds['reward_inc_rr'] = keep
            ## Note: there can be "reward" cells that are not also "rr" if both of their
            ## peaks are within 50 cm of reward but not within 50 cm of each other relative to reward
            ## (because a 100 cm span is allowed on either side of reward)

        if exclude_rr_from_others:
            if (
                (celltype != 'rr') and np.isin(day, [3,5,7,8,10,12,14])): #celltype != 'rr'
                keep = _exclude_rr(keep, celltype, verbose=verbose)

                n_out[celltype] = len(keep)
                inds[celltype] = keep
        else:
            n_out[celltype] = len(keep)
            inds[celltype] = keep
        # print('not excluding RR cells from any category')
        

    classified_inds = np.concatenate([inds[ct] for ct in inds.keys()])
    # check for duplicates in the exclusive categories:
    check_inds = np.concatenate([inds[ct] for ct in ['track', 'appear', 'disappear', 'rr', 'nonreward_remap']])
    if len(check_inds) != len(np.unique(check_inds)):
        print('duplicates detected')
        
    unclassified = np.where(_multiDayData[day].overall_place_cell_masks[an])[0][
        ~np.isin(np.where(_multiDayData[day].overall_place_cell_masks[an])[0], classified_inds)]
    
    n_out['unclassified'] = len(unclassified)
    inds['unclassified'] = unclassified
    
    return n_out, inds
# Preprocessing guide

This is meant to serve as a reference for how data were preprocessed from the raw imaging/VR files to the several levels of data structures used for analysis.

All file paths are written as if we are in the current repo, i.e. the pip installable modules will be listed as `./src/reward_relative`  \
If I say "module" I mean to look for a .py file in `./src/reward_relative`  \

### Directory structure

* data_root: e.g. `/data/`
    * `2P_Data` (sometimes omitted locally)
        * animal
            * date: dd_mm_yyyy
                * scene: e.g. Env1_LocationA
                    * If you copied the scanbox files locally, they would be here as .sbx and .mat alongside the below directory
                    * session + scan directory: e.g. Env1_LocationA_002_001; session (index of Unity VR file) = 002, scan number (index of scan in Scanbox) = 001
                        * suite2p
                            * plane0 (plane1, combined, etc if multiplane)
    * `VR_Data`
        * animal
            * date: dd_mm_yyy
                * SQLite files: scene_session.sqlite, e.g. Env1_LocationA_2.sqlite

### Order of operations:

0. Update `./src/reward_relative/sessions_dict.py` with the metadata from each recording session, with one dictionary entry per animal in either `single_plane` or `multi_plane`
    1. Include date, scene name, session, scan number, experiment day (1-indexed)
1. Extract binaries, run suite2p to do motion correction and find ROIs
    1. In `./notebooks/suite2p_notebooks`, duplicate an existing notebook and rename for the current animal
    2. Manually edit with the sessions you want to process
    3. Manually edit any suite2p parameters you want to change (for example, if you think the expression was weak, you could lower threshold_scaling from 1 to 0.6-0.8)
    4. For Scanbox data, running the main notebook cell will convert the .sbx files to .h5 and then run suite2p
2. Curate cells in the suite2p GUI
    1. `iscell.npy` is automatically updated and saved during curation
    2. Be sure to backup curated data so you don't lose all that work!
3. Copy VR_Data to the local machine with rclone or similar
4. Make `sess` class which aligns imaging data to Unity VR data.
    1. The code for the class object itself is in a separate repo, `TwoPUtils` 
    2. The function that actually interpolates/aligns VR data to the slower imaging frame rate is `vr_align_to_2P` in `TwoPUtils/preprocessing.py`
    3. Use `./notebooks/make_session_pkl.ipynb` to make sess for each animal and list of experiment days that you want.
    4. `sess` pickles will be saved in `/data_root/sess/`
    5. Note `sess` does not contain deltaF/F -- this happens next, because it is more customizable. The idea is that you should only ever have to make the `sess` class once.
5. Make `multi_anim_sess` dictionary to collect and post-process sess across animals.
    1. Use `./notebooks/make_multi_anim_sess.ipynb`
    2. The core function `multi_anim_sess` in the `utilities` module runs functions to compute deltaF/F (dFF), calculates place cells from shuffles, and adds details like a trial set dictionary.
        1. The function that actually computes dFF is `dff` in the `preprocessing` module
    2. All of these are collected with the sess data for multiple animals on a single day, and stored in a dictionary where each top entry is an animal name. 
    3. The notebook then saves this `multi_anim_sess` as a pickle so that we can work off a constant set of place cell IDs.
        1. TO-DO to free up disk space: save the sess pickle path as a pointer rather than re-saving the whole class inside multi_anim_sess
6. Align ROIs across days (can happen at any time after making sess)
    1. Use `./notebooks/Run_ROI_Aligner.ipynb`
    2. Saves matched ROI pair indices in `/data_root/sess/<animal>/roi_aligned_results.pkl`
7. For most analyses in Sosa, Plitt, Giocomo 2024, it is then necessary to create a `dayData` class for each experiment day, across animals.
    1. Use `./notebooks/make_multiDayData_class.ipynb`. `./reward_relative/dayData` has its own module with some helper functions. This `dayData` class contains computationally-intensive results like identifying reward-relative cells compared to a trial-by-trial shuffle of their activity.
8. Run remaining analyses and plot figures in `./notebooks` (more notebook figures will be posted as they are cleaned up for readability and documented).


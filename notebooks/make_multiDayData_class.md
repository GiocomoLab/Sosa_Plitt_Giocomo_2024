---
jupyter:
  jupytext:
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.13.4
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Run dayData module to create multiDayData for analysis

multiDayData is a dictionary where each entry holds the dayData class for a single day,  \
where each dayData class runs calculations such as finding circular distances between  \
reward-relative spatial firing peaks and comparing to a shuffle, for each animal.  \
Most attributes of dayData have an entry for each animal.

Requires `multi_anim_sess` to already be saved for each day, which is a dictionary containing  \
the sess data, dF/F, and place cell booleans for each animal. 


```python tags=[]
%matplotlib inline
# inline, widget

import os
import pickle
import dill
import numpy as np
import warnings
from datetime import datetime

from reward_relative import utilities as ut
from reward_relative import dayData as dd
    

%load_ext autoreload
%autoreload 2

save_figures = False
```

```python
from reward_relative.path_dict_firebird import path_dictionary as path_dict
path_dict
```

# Create multiDayData class for each experiment day

```python tags=[]
## Specify parameters (these are already defaults in dayData class)
bin_size = 10  # for quantifying distribution of place field peak locations
sigma = 1  # for smoothing
smooth = False  # whether to smooth for finding place cell peaks
exclude_int = True  # exclude putative interneurons
int_thresh = 0.5
impute_NaNs = True # whether to impute (interpolate) bins that are NaN in spatially-binned data

## Place cell definitions:
## 'and' = must have significant spatial information 
##        in trial set 0 AND trial set 1 (i.e. before and after the reward switch)
## 'or' = must have signitive spatial information in trial set 0 OR trial set 1
place_cell_logical = 'or' 
ts_key = 'dff' # which timeseries to use for finding peaks
use_speed_thr = True # use a speed threshold to calculate new trial matrices
speed_thr = 2 # speed threshold in cm/s (excludes data at speed less than this)

reward_dist_inclusive = 50 #in cm
reward_dist_exclusive = 50 #in cm
reward_overrep_dist = 50 #in cm

experiment = 'MetaLearn'
year = 'combined'

if experiment == 'NeuroMods':
    # exp_days = [1, 3, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17]
    exp_days = [8, 10, 12, 14, 15, 17]
elif experiment == 'MetaLearn':
    # exp_days = [1,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14] # all days
    exp_days = [3, 5, 7, 8, 10, 12, 14] # switch days
    # exp_days = [1,2,4,6,9,11,13] # "stay" days


# create a tag to label the filename with params
tag = ''
if smooth:
    tag = ('smoothed_sig%d' % sigma)
else:
    tag = 'unsmoothed'

if exclude_int:
    tag = tag + ('_excInt%.1f' % int_thresh)

tag = tag + ('_inc%d' % reward_dist_inclusive)

if use_speed_thr:
    tag = tag + '_useSpeed'

# For loading individual day pickles
day_params={'speed': str(speed_thr),
          'nperms': 100, # shuffles for defining place cells
          'baseline_method': 'maximin', # dF/F method
          'ts_key': 'events' # timeseries used for identifying place cells
          }

multiDayData = dict()

add_all_computations = False


with warnings.catch_warnings():
    warnings.simplefilter("ignore", category=RuntimeWarning)

    for d_i, exp_day in enumerate(exp_days):

        anim_list = dd.define_anim_list(experiment, exp_day, year=year)

        print(anim_list)

        multi_anim_sess = dd.load_multi_anim_sess(path_dict, exp_day, anim_list,
                                                  params=day_params
                                                  )

        # initialize class with basic info
        multiDayData[exp_day] = dd.dayData(anim_list,
                                           multi_anim_sess,
                                           exp_day=exp_day,
                                           experiment=experiment,
                                           # timeseries to use
                                           ts_key=ts_key,  # to use for analysis, reward cell fractions,
                                           #                                            # finding place cell peaks
                                           force_two_sets=True,  # of trials
                                           use_speed_thr=use_speed_thr,
                                           speed_thr=speed_thr,
                                           exclude_int=exclude_int,
                                           int_thresh=int_thresh,
                                           int_method='speed',
                                           reward_dist_exclusive=reward_dist_inclusive,
                                           reward_dist_inclusive=reward_dist_exclusive,
                                           reward_overrep_dist=reward_overrep_dist,
                                           )

        # add things to the class that are computationally intensive/time-consuming
        if add_all_computations:
            multiDayData[exp_day].add_all_the_things(anim_list, 
                                                    multi_anim_sess,
                                                    add_behavior=True,
                                                    add_cell_classes=True,
                                                    add_circ_relative_peaks=True,
                                                    add_field_dict=True,
                                                    bin_size=bin_size,  # for quantifying distribution of place field peak locations
                                                    sigma=sigma,  # for smoothing
                                                    smooth=smooth,  # whether to smooth for finding place cell peaks
                                                    # (activity will be auto smoothed for everything else)
                                                    impute_NaNs=True,

                                                    place_cell_logical=place_cell_logical,
                                                    ts_key=ts_key,
                                                    lick_correction_thr=0.35,
                                                    )

        %reset_selective -f multi_anim_sess
```

```python
# print attributes of dayData class for day 3
multiDayData[3].__dict__.keys()
```

```python tags=[]
max_anim_list = sorted(np.unique(np.concatenate([multiDayData[day].anim_list
                                                     for day in exp_days])), 
                           key=len)
max_anim_list
```

```python
multiDayData.keys()
```

```python
include_ans = multiDayData[exp_days[-1]].circ_rel_stats_across_an['include_ans']
include_ans
```

## Save multiDayData as pickle

```python
from datetime import datetime

pkl_name = "%s_expdays%s_multiDayData_%s_%s_%s.pickle" % (ut.make_anim_tag(max_anim_list),
                                                          ut.make_day_tag(
                                                              exp_days),
                                                          ts_key,
                                                          tag,
                                                          datetime.now().strftime("%Y%m%d-%H%M"))
print(pkl_name)
file_dir = os.path.join(path_dict['preprocessed_root'], 'multiDayData')
ut.write_sess_pickle(multiDayData, file_dir, pkl_name, overwrite=False)
```

import numpy as np
import scipy as sp
import dask
from sklearn.linear_model import LinearRegression as linreg

import warnings

from . import behavior as behav
from . import utilities as ut
# from dask.diagnostics import ProgressBar


def xcorr(in1, in2, mode='same', window=None, bin_time=None, zscore=True):
    '''
    Compute a cross-correlation on two 1D arrays using
        scipy.signal.correlate, and returns the xcorr in
        Pearson correlation units. This requires z-scoring
        each input and dividing by the number of samples (n-1)
        (assuming both inputs are the same length)

    NOTE: in2 is the signal that moves relative to in1.
        A positive-shifted therefore peak means in2 leads in1, because
        in2 had to be shifted positively to maximize correlation with in1.

    Optionally will also only output the xcorr within a specified lag window
        using the "window" and "bin_time" arguments.
        window: length of window (+/-) around 0 to keep
            e.g. if window=2 (seconds), the total xcorr will be 4 sec long
        bin_time: amount of time per sample (e.g. frame time, in seconds)

    Outputs:
        xcorr: The cross-correlation in Pearson units
        lags: the lag indices or times (if window is specified)

    '''

    # First z-score each input
    if zscore:
        in2 = ut.zscore(np.copy(in2))
        in1 = ut.zscore(np.copy(in1))

    in2_len = len(in2)
    in1_len = len(in1)

    if in2_len != in1_len:
        print('WARNING: Input lengths are not equal. X-corr will compute, but z-scoring may be incorrect!')

    if zscore:
        x_corr = sp.signal.correlate(in1, in2, mode=mode) / (in1_len - 1)
    else:
        x_corr = sp.signal.correlate(in1, in2, mode=mode) / (in1_len - 1)

    lags = xcorr_lags(in1_len, in2_len, mode=mode)

    if window is not None:
        if bin_time is None:
            warnings.warn("Must specify a bin time to use the 'window' option")
            raise NotImplementedError
        else:
            timelags = lags * bin_time
            inds_in_win = np.where(np.logical_and(
                timelags > -window, timelags < window))[0]

        window_len = np.arange(-window, window, bin_time).shape[0] - 1
        if len(inds_in_win) < window_len:
            warnings.warn("Fewer samples than length of desired window")

        lags = timelags[inds_in_win]
        x_corr = x_corr[inds_in_win]

    return x_corr, lags


def xcorr_lags(in1_len, in2_len, mode='same'):
    '''
    COPIED FROM scipy.signal.correlation_lags in scipy 1.7.1
    '''

    """
    Calculates the lag / displacement indices array for 1D cross-correlation.
    Parameters
    ----------
    in1_size : int
        First input size.
    in2_size : int
        Second input size.
    mode : str {'full', 'valid', 'same'}, optional
        A string indicating the size of the output.
        See the documentation `correlate` for more information.
    See Also
    --------
    correlate : Compute the N-dimensional cross-correlation.
    Returns
    -------
    lags : array
        Returns an array containing cross-correlation lag/displacement indices.
        Indices can be indexed with the np.argmax of the correlation to return
        the lag/displacement.
    Notes
    -----
    Cross-correlation for continuous functions :math:`f` and :math:`g` is
    defined as:
    .. math ::
        \left ( f\star g \right )\left ( \tau \right )
        \triangleq \int_{t_0}^{t_0 +T}
        \overline{f\left ( t \right )}g\left ( t+\tau \right )dt
    Where :math:`\tau` is defined as the displacement, also known as the lag.
    Cross correlation for discrete functions :math:`f` and :math:`g` is
    defined as:
    .. math ::
        \left ( f\star g \right )\left [ n \right ]
        \triangleq \sum_{-\infty}^{\infty}
        \overline{f\left [ m \right ]}g\left [ m+n \right ]
    Where :math:`n` is the lag.
    Examples
    --------
    Cross-correlation of a signal with its time-delayed self.
    >>> from scipy import signal
    >>> from numpy.random import default_rng
    >>> rng = default_rng()
    >>> x = rng.standard_normal(1000)
    >>> y = np.concatenate([rng.standard_normal(100), x])
    >>> correlation = signal.correlate(x, y, mode="full")
    >>> lags = signal.correlation_lags(x.size, y.size, mode="full")
    >>> lag = lags[np.argmax(correlation)]
    """

    # calculate lag ranges in different modes of operation
    if mode == "full":
        # the output is the full discrete linear convolution
        # of the inputs. (Default)
        lags = np.arange(-in2_len + 1, in1_len)
    elif mode == "same":
        # the output is the same size as `in1`, centered
        # with respect to the 'full' output.
        # calculate the full output
        lags = np.arange(-in2_len + 1, in1_len)
        # determine the midpoint in the full output
        mid = lags.size // 2
        # determine lag_bound to be used with respect
        # to the midpoint
        lag_bound = in1_len // 2
        # calculate lag ranges for even and odd scenarios
        if in1_len % 2 == 0:
            lags = lags[(mid - lag_bound):(mid + lag_bound)]
        else:
            lags = lags[(mid - lag_bound):(mid + lag_bound) + 1]
    elif mode == "valid":
        # the output consists only of those elements that do not
        # rely on the zero-padding. In 'valid' mode, either `in1` or `in2`
        # must be at least as large as the other in every dimension.

        # the lag_bound will be either negative or positive
        # this let's us infer how to present the lag range
        lag_bound = in1_len - in2_len
        if lag_bound >= 0:
            lags = np.arange(lag_bound + 1)
        else:
            lags = np.arange(lag_bound, 1)
    return lags


def run_shuffle_xcorr(full_in1,
                      full_in2,
                      axis_to_shuffle=0,  # axis to shuffle across
                      axis_to_mean=None,
                      n_perms=500,
                      **kwargs):
    """
    Calculate the xcorr relative to a shuffle using parallelization across CPU threads.

    find the peak xcorr that exceeds 95% (the upper 97.5%) 
    of the shuffle distribution. If axis_to_mean is an integer, xcorr is performed
    on the mean across axis_to_mean after shuffling in axis_to_shuffle.

    """

    delayed_results = dask.delayed(shuffle_xcorr)(
        full_in1, full_in2,
        axis_to_shuffle=axis_to_shuffle,
        axis_to_mean=axis_to_mean,
        n_perms=n_perms,
        **kwargs)

    # with ProgressBar():
    results = dask.compute(delayed_results, scheduler='processes')

    return results


def shuffle_xcorr(in1, in2,
                  axis_to_shuffle=0,  # axis to shuffle across
                  axis_to_mean=None,
                  n_perms=500,
                  zscore=False,
                  **kwargs):

    # trial_avg map
    if axis_to_mean is not None:
        in1_ = np.nanmean(in1, axis=axis_to_mean)
        in2_ = np.nanmean(in2, axis=axis_to_mean)
    else:
        in1_ = np.copy(in1)
        in2_ = np.copy(in2)

    xc_vec, lags = xcorr(in1_, in2_, mode='same', **kwargs)
    # if zscore:
    #     xc_vec = sp.signal.correlate(ut.zscore(in1_),
    #                                  ut.zscore(in2_), mode="same") / (len(ut.zscore(in1_))-1)
    # else:
    #     xc_vec = sp.signal.correlate(in1_, in2_, mode="same") / (len(in1_)-1)

    xc_mat_perm = np.zeros((n_perms, len(lags)))*np.nan

    for perm in range(n_perms):
        tmp_in2 = np.copy(in2)
        if len(in2.shape) == 1:

            tmp_in2 = np.roll(
                tmp_in2, np.random.randint(
                    1, high=tmp_in2.shape[axis_to_shuffle]),
                axis=axis_to_shuffle)
        elif len(in2.shape) > 2:
            raise NotImplementedError(
                'Not implemented for array dimensions greater than 2')
        else:
            for t in range(in2.shape[axis_to_shuffle]):
                if axis_to_shuffle == 0:
                    tmp_in2[:, t] = np.roll(
                        tmp_in2[:, t], np.random.randint(
                            1, high=tmp_in2.shape[axis_to_shuffle]),
                        axis=axis_to_shuffle)
                elif axis_to_shuffle == 1:
                    tmp_in2[t, :] = np.roll(
                        tmp_in2[t, :], np.random.randint(
                            1, high=tmp_in2.shape[axis_to_shuffle]),
                        axis=axis_to_shuffle)

        if axis_to_mean is not None:
            tmp_in2 = np.nanmean(tmp_in2, axis=axis_to_mean)

        xc_mat_perm[perm, :], _ = xcorr(
            in1_, tmp_in2.squeeze(), mode='same', **kwargs)
        # if zscore:
        #     xc_mat_perm[perm, :] = sp.signal.correlate(ut.zscore(in1_),
        #                                                ut.zscore(tmp_in2.squeeze()),
        #                                                mode="same") / (len(ut.zscore(in1_))-1)
        # else:
        #     xc_mat_perm[perm, :] = sp.signal.correlate(in1_,
        #                                                tmp_in2.squeeze(),
        #                                                mode="same") / (len(in1_)-1)

    xc_shuf_mean = np.nanmean(xc_mat_perm, axis=0)
    xc_shuf_CI_low = np.percentile(xc_mat_perm, 2.5, axis=0)
    xc_shuf_CI_hi = np.percentile(xc_mat_perm, 97.5, axis=0)

    above_shuf = xc_vec > xc_shuf_CI_hi
    if np.any(above_shuf):
        xc_peaks_above_shuf_tmp = lags[above_shuf][
            ut.nanargmax(xc_vec[above_shuf])]
    else:
        xc_peaks_above_shuf_tmp = np.nan

    xc_shuf = {'mean': xc_shuf_mean,
               'CI_lo': xc_shuf_CI_low, 'CI_hi': xc_shuf_CI_hi}

    return {'lags': lags, 'xc_true': xc_vec, 'shuffle': xc_shuf, 'xc_peak_above_shuffle': xc_peaks_above_shuf_tmp}


def lickspeed_xcorr(sess, window=4, trial_subset=None, mode='same'):
    """
    xcorr of licking with speed within each trial
    """

    lickrate = behav.lickrate(sess)
    frame_time = behav.frametime(sess)
    speed = sess.timeseries['speed'][0]

    xc_out = dict()

    # Choose trial subset
    if trial_subset is not None:
        trial_starts = sess.trial_start_inds[trial_subset]
        trial_stops = sess.teleport_inds[trial_subset]
    else:
        trial_starts = sess.trial_start_inds
        trial_stops = sess.teleport_inds

    window_len = np.arange(-window, window, frame_time).shape[0]-1

    # initialize trial matrices
    lickspeed_trial_mat = np.zeros((len(trial_starts), window_len))*np.nan

    for i, (t_start, t_end) in enumerate(zip(trial_starts, trial_stops)):
        if t_start == 0:  # happens if "G" was pressed too early, missed the first trial start TTL
            continue

        trial_licks = lickrate[t_start-1:t_end-1]
        trial_licks = ut.zscore(trial_licks)
        trial_speed = speed[t_start-1:t_end-1]
        trial_speed = ut.zscore(trial_speed)

        in2_len = len(trial_licks)
        in1_len = len(trial_speed)

        trial_xc, lags = xcorr(trial_licks, trial_speed,
                               mode=mode, window=window, bin_time=frame_time)

        inds_in_win = np.where(np.logical_and(
            lags > -window, lags < window))[0]

        if len(inds_in_win) < window_len:
            print(f'trial {0} less time than window, skipping')
            continue
        else:
            lickspeed_trial_mat[i, :] = trial_xc

    # I expect to see RuntimeWarnings in this block
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=RuntimeWarning)
        xc_out['lags'] = lags

        xc_out['mean_lickspeed'] = np.nanmean(lickspeed_trial_mat,
                                              axis=0,
                                              keepdims=True)
        xc_out['sem_lickspeed'] = ut.sem(lickspeed_trial_mat,
                                         axis=0)

    return xc_out

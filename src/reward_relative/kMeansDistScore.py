import sys
sys.path.append("/home/mari/local_repos/lvl")
# uses Alex William's lvl repo: https://github.com/ahwillia/lvl
from lvl.factor_models import KMeans as lvl_kmeans
from lvl.factor_models import NMF as lvl_soft_kmeans
from lvl.resamplers import RotationResampler
from lvl.crossval import speckled_cv_scores 
from sklearn.metrics import silhouette_samples, silhouette_score
from scipy.spatial.distance import pdist, squareform

from scipy.spatial.distance import pdist, squareform
from sklearn.impute import KNNImputer
from scipy.optimize import curve_fit

import sys
import numpy as np
import scipy as sp
import pandas as pd
from tqdm import tqdm

# Isabel Low's functions
def clu_distance_population(Y, H, map_idx):
    '''
    Calculate the distance between the population activity and 
    the k-means cluster centroids on each trial

    Params:
    ------
    Y : ndarray
        normalized firing rate by 5cm position bins by trial for each cell
        shape (n_trials, n_pos_bins, n_cells)
    H : ndarray
        k-means tuning curve estimates for each cluster/map
        shape (n_maps, n_cell*n_pos_bins)
    map_idx : int
        index for map 1

    Returns:
    -------
    dist : ndarray
        distance to cluster on each trial; shape (n_trials, )
        1 = in map 1 centroid
        -1 = in map 2 centroid
        0 = exactly between the two maps
    '''
    # reshape Y to get a trial x neurons*positions matrix
    Y = Y.transpose(0, 2, 1)
    Y_unwrapped = np.reshape(Y, (Y.shape[0], -1))
    n_trials, n_cells, n_pos = Y.shape

    # get kmeans centroids
    c1 = H[map_idx]
    c2 = H[map_idx-1]
    
    # project everything down to a vector connecting the two centroids
    proj = (c1 - c2) / np.linalg.norm(c1 - c2)
    projc1 = c1 @ proj # cluster 1
    projc2 = c2 @ proj # cluster 2
    projY = Y_unwrapped @ proj # activity on each trial
    
    # get distance to cluster on each trial
    dd = (projY - projc2) / (projc1 - projc2)
    return 2 * (dd - .5) # classify -1 or 1

def clu_distance_cells(Y, H, map_idx, W):
    '''
    Calculate the distance to k-means cluster for each cell on each trial.
    Also computes the log-likelihood that each cell is in each map or the "remap score."

    Params:
    ------
    Y : ndarray
        normalized firing rate by 5cm position bins by trial for each cell
        shape (n_trials, n_pos_bins, n_cells)
    H : ndarray
        k-means tuning curve estimates for each cluster/map
        shape (n_maps, n_cell*n_pos_bins)
    map_idx : int
        index for map 1
    W : ndarray
        k-means cluster label for each trial; shape (n_trials, n_maps)

    Returns:
    -------
    dd_by_cells : ndarray
        distance to cluster for each cell on each trial; shape (n_cells, n_trials)
        1 = in map 1 centroid
        -1 = in map 2 centroid
        0 = exactly between the two maps
    ll_cells : ndarray
        log likelihood that each cell is in each map; shape (n_cells, n_trials)
        0 = at the midpoint between clusters
        1 = in either cluster centroid
    '''
    # reshape and get the dimensions 
    Y = Y.transpose(0, 2, 1)
    n_trials, n_cells, n_pos = Y.shape
    n_maps = H.shape[0]
    H_tens = H.reshape((n_maps, n_cells, n_pos))

    # get each cluster
    c1 = H_tens[map_idx, :, :]
    c2 = H_tens[map_idx-1, :, :]
    
    # find the unit vector in direction connecting c1 and c2 in state space
    proj = (c1 - c2) / np.linalg.norm(c1 - c2, axis=1, keepdims=True)

    # project everything onto the same line
    projc1 = np.sum(c1 * proj, axis=1)[None, :]
    projc2 = np.sum(c2 * proj, axis=1)[None, :]
    projY = np.sum(Y * proj[None, :, :], axis=2)

    # distance to cluster for each cell on each trial
    # assign 1 for in map 1 and -1 for in map 2
    dd_by_cells = (projY - projc2) / (projc1 - projc2)
    dd_by_cells = 2 * (dd_by_cells - .5)
    dd_by_cells = dd_by_cells.T
    
    # get the ideal distribution (k-means label for each trial)
    n_cells = dd_by_cells.shape[0]
    K = np.tile(W[:, map_idx-1], (n_cells, 1))

    # calculate log likelihood - this is the "remap score"
    ll_cells = K * np.log(1 + np.exp(dd_by_cells)) + (1 - K) * np.log(1 + np.exp(-dd_by_cells))

    return dd_by_cells, ll_cells


## find optimal k and compare to one-map shuffle
## modelled after Charlotte's code
def optimal_k(Y_in,  max_k = 4, k_reps=10, shuffle_reps = 10, alpha=0.05, verbose=True, shuffle_method='lvl'):
    """ 
    Run k-means ten times and choose the k that
    maximizes the average silhouette score, then compares
    test performance at that k to the rotation shuffle from Alex W
    to ask if clustering at the current k is significantly better than
    you'd get from a session with one map.
    
    """
    extended_k = np.arange(1, max_k+1, 1)
    possible_k = np.arange(2, max_k+1, 1)

    silhouette_reps = np.zeros((k_reps, len(possible_k)))
    
    if len(Y_in.shape) > 2:
        Y_2d = Y_in.transpose(0, 2, 1).reshape((Y_in.shape[0], -1))
    else:
        Y_2d = np.copy(Y_in)
    
    for p in range(k_reps):
        for n, k in enumerate(possible_k):     
            # fit model and get params
            model_kmeans = lvl_kmeans(n_components = k, n_restarts = 100)
            model_kmeans.fit(Y_2d)
            W, _ = model_kmeans.factors
            # each row of W is a one-hot vector marking the column as the map label
            # so get the column IDs
            labels = np.where(W == 1)[1] #.astype(float)
            silhouette_reps[p,n] = silhouette_score(Y_2d, labels)

    best_k = possible_k[np.argmax(np.mean(silhouette_reps, axis = 0))]
    
    #compare test R^2 vs. shuffle for k = 1-4
    # Run cross-validated k-means with speckled holdout pattern.
    km_train_scores = np.ones((max_k, shuffle_reps))
    km_test_scores = np.ones((max_k, shuffle_reps))

    for i, rank in tqdm(enumerate(extended_k)):
        model = lvl_kmeans(n_components=rank, n_restarts=100, maxiter=1000)
        km_train_scores[i], km_test_scores[i] = \
            speckled_cv_scores(model, Y_2d, n_repeats=shuffle_reps)

    # Run cross-validated k-means on shuffled/resampled dataset.
    shuff_km_train_scores = np.ones((max_k, shuffle_reps))
    shuff_km_test_scores = np.ones((max_k, shuffle_reps))

    if shuffle_method == 'manual':
        Y_shuf = np.copy(Y_in) #Y_pv_corr[:,:,np.newaxis]

        for t in range(Y_shuf.shape[0]):
            Y_shuf[t,:,:] = np.roll(Y_shuf[t, :, :], 
                                    np.random.default_rng().integers(
                                        0, Y_shuf.shape[1]), axis=1)

        Y_shuf_unwrapped = Y_shuf.transpose(0, 2, 1).reshape((Y_shuf.shape[0], -1))
        Y_shuf_sim_vec = np.abs(pdist(Y_shuf_unwrapped, 'correlation')-1)
        Y_shuf_sim = squareform(Y_shuf_sim_vec)

        for i, rank in tqdm(enumerate(extended_k)):
            model = lvl_kmeans(n_components=rank, n_restarts=100, maxiter=1000)
            shuff_km_train_scores[i], shuff_km_test_scores[i] = \
                speckled_cv_scores(model, Y_shuf_unwrapped, n_repeats=shuffle_reps)
    elif shuffle_method == 'lvl':
        for i, rank in tqdm(enumerate(extended_k)):
            model = lvl_kmeans(n_components=rank, n_restarts=100, maxiter=1000)
            shuff_km_train_scores[i], shuff_km_test_scores[i] = \
                speckled_cv_scores(model, Y_2d, n_repeats=shuffle_reps, resampler=RotationResampler())
    
    model_kmeans = lvl_kmeans(n_components = best_k, n_restarts = 100)
    model_kmeans.fit(Y_2d)
    W, H = model_kmeans.factors
    Y_hat = model_kmeans.predict()
    score = model_kmeans.score(Y_2d)
    if verbose:
        print(f"best k = {best_k}")
        print(score)

    #check if sig difference in the distribution of test R^2 real vs. shuffle data at optimal k:
    chosenkidx = np.where(extended_k == best_k)[0]
    res = sp.stats.wilcoxon(km_test_scores[chosenkidx,:][0], 
                            shuff_km_test_scores[chosenkidx,:][0], alternative = 'greater')
    res_train = sp.stats.wilcoxon(km_train_scores[chosenkidx,:][0], 
                                  shuff_km_train_scores[chosenkidx,:][0], alternative = 'greater')
    onemap = []
    if res.pvalue <= alpha:
        if verbose:
            print('outperforms shuffle at optimal k = ' + str(best_k))
            print('stat = %.2f, p = %.4e' % (res.statistic, res.pvalue))
            print('train stat = %.2f, p = %.4e' % (res_train.statistic, res_train.pvalue))           
        onemap = np.append(onemap, [False, res.statistic, res.pvalue])
    else:
        if verbose:
            print('does not outperform shuffle, probable one map session')
            print('stat = %.2f, p = %.4e' % (res.statistic, res.pvalue))
            print('train stat = %.2f, p = %.4e' % (res_train.statistic, res_train.pvalue))           
            
        onemap = np.append(onemap, [True, res.statistic, res.pvalue])
    
    return best_k, score, onemap